\newif\ifcomments\commentsfalse

\RequirePackage[svgnames,dvipsnames,prologue]{xcolor}

\documentclass[format=acmsmall,manuscript,screen,nonacm,margin=1in,11pt]{acmart}

\usepackage{typeclasses}

\title{Dialects for Type Computations}
% \subtitle{Typeclasses, functional and Type Families}
\author{Apoorv Ingle}
%\orcid{0000-0002-7399-9762}
\affiliation{%
  \institution{University of Iowa}
  \department{Department of Computer Science}
  \streetaddress{McLean Hall}
  \city{Iowa City}
  \state{Iowa}
  \country{USA}}
% \keywords{typeclass, type family}

\begin{document}
\begin{abstract}
  Static types have two advantages: (1) they serve as a guiding tool
  to help programmers write correct code, and (2) the compiler
  can help identify code that does not behave correctly.
  An expressive type system can guarantee stronger claims about programs.
  Type level computations make the type system more expressive.
  In Haskell, there are two styles of type level computation---functional dependencies
  and type families. In this report we describe illustrate,
  formalize, and compare these two language features.
\end{abstract}
\maketitle
%\pagestyle{plain}

\section{Introduction}
Parametric polymorphism is a powerful technique that allows programs to work on
a wide variety of types. The identity function, which takes an input and returns it
without modification has the type !$\forall$$\alpha$. $\alpha$ -> $\alpha$!.
We read this type as: for all types !$\alpha$!, if the argument is of type !$\alpha$!
then the function returns a value of the type !$\alpha$!.
We also need to tame unconstrained polymorphism.
A division function does not make sense on all types. We cannot
divide a function, which multiplies two numbers, by another function, which adds two numbers.
The type !$\forall$ $\alpha$. ($\alpha\times\alpha$) -> $\alpha$!, that accepts
a pair of values of type !$\alpha$!, and returns the first argument divided by the
second argument is too general to describe division. A constrained polymorphic type,
!$\forall$ $\alpha$. (Dividable $\alpha$) => ($\alpha\times\alpha$) -> $\alpha$!,
more accurately describes the functions intention. Intuitively, the predicate,
!Dividable $\alpha$!, means: only those types have a meaningful divide function
that satisfy this predicate. Typeclasses\cite{wadler_polymorphism_1989} give a mechanism
of having such constrained polymorphic types. The theory of qualified types\cite{jones_qualified_1994}
formalizes typeclasses and justifies constrained polymorphism
without compromising type safety by having predicates as a part of type syntax.

A typeclass defines a relation on types. This gives programmers a way to
perform computations at type level. However, using relations to perform type computations
is cumbersome. A new language feature, type families\cite{schrijvers_towards_2007}, was introduced in Haskell
to enable partial type functions. They are stylistically more obvious for functional programmers.
Naturally, type families warrants a richer system of types, and reasoning about type safety
for such systems is nontrivial.

The scope of the current article is as follows:
we first describe typeclasses in \pref{sec:tc},
and then describe functional dependencies\cite{jones_tcfd_2000} with some examples in \pref{subsec:fd}.
We formalize them in \pref{subsec:tc-formal} and describe their consequences in \pref{subsec:fd-improve}.
We have a brief discussion about associated types as a way to have type functions in \pref{sec:assoc-types}.
We then describe two flavors of type families---closed type families\cite{eisenberg_typefamilies_2014}
in \pref{sec:tf-closed} and constrained type families\cite{morris_typefamilies_2017}
in \pref{sec:tf-constrained}.
We formalize the important portions of both the systems in \pref{subsec:tf-closed-formal}
and \pref{subsec:tf-constrained-formal} respectively to state the type consistency property.
To conclude, we point towards some open questions in \pref{sec:conclusion}.
For presenting code examples, we will be using Haskell\cite{haskell_2010} like syntax.

\section{Typeclasses}\label{sec:tc}
Typeclasses can be thought of as predicates on types. Each typeclass is accompanied by its member
functions that all the instances support. For example,
equality can be expressed as a typeclass !Equal a! shown below:\newline
{
  \begin{tabularx}{\textwidth}{X X X}
\begin{code}^^J
class Equal a where^^J
\ \ eq::(a$\times$a) -> Bool^^J
\end{code}&%
\begin{code}^^J
instance Equal Int where^^J
\ \ eq(a,b) = primEQInt(a,b)^^J
\end{code}&%
\begin{code}^^J
instance Equal Char where^^J
\ \ eq(a,b) = primEQChar(a,b)^^J
\end{code}
  \end{tabularx}
}
The instances of !Equal a! typeclass can be types such as integers (!Int!) and characters (!Char!).
We say that !Int! and !Char! satisfy the predicate !Equal a!. An equality instance on function types (!a->b!)
is not meaningful. The function !eq! is not truly polymorphic: it cannot operate on function types. Rather,
it is constrained to only those types that have an !Equal! instance defined.
We make it explicit in the type of this function, !$\forall$a.Equal a => (a$\times$a) -> Bool!.
We read this type as: for any type !a! satisfying the predicate !Equal a!, the function
when given an argument of a pair type, !(a$\times$a)!, returns a value of type !Bool!.

\begin{figure}[ht]
  \begin{tabularx}\textwidth{X X}
\begin{code}^^J
class Addition m n p where^^J
\ \ add :: ($\texttt{m} \times \texttt{n}$) -> p^^J
^^J
instance Addition Float Float Float^^J
\ \ add (f1, f2) = primAddF (f1, f2)^^J
^^J
-- expr :: (Addition Int Float b, Addition b Int c) => c^^J
expr = add (add (1, 2.5), 3)^^J
\end{code}&%
\begin{code}^^J
instance Addition Int Float Float where^^J
\ \ add (i, f) = primAddF ((toFlt i), f)^^J
^^J
instance Addition Int Float Int where^^J
\ \ add (i, f) = primAddI (i, (trucFtoI f))^^J
\end{code}
  \end{tabularx}
  \caption{Multiparameter Typeclasses}
  \label{fig:multip-typeclass}
\end{figure}

%% What are these?
There is nothing special about typeclasses having just one type parameter. 
A multiparameter typeclass with $n$ type parameters represents a relation on $n$ types.
An example, !Addition m n p! is shown in \pref{fig:multip-typeclass}.
It represents a relation on types !m!, !n! and !p! such that, adding values of type !m! and type !n!
returns a value of type !p!. The type of the function, !add!, which performs the addition operation,
is given as !$\forall$a b c. Addition a b c => (a $\times$ b) -> c!. Instances of such a typeclass would be
!Addition Float Float Float!, !Addition Int Float Float!, and so on.

%% What problems do they introduce?
Although more general than single parameter typeclasses, multiparameter typeclasses can be
difficult to use in practice. Suppose, the programmer defines two instances:
!Addition Int Float Float! and !Addition Int Float Int!
and writes an term !expr = add(add(1,2.5), 3)!.
Due to the use of the function !add! in !expr!, its most general type synthesized
by the type inference algorithm will be !$\forall$ b c. (Addition Int Float b, Addition b Int c) => c!.
Notice how the type variable !b! occurs only in the predicate set !(Addition Int Float b, Addition b Int c)!.
Such types are called ambiguous types and the type variables, such as !b!,
are called ambiguous type variables. Ambiguous types do not have well defined semantics.
The compiler cannot choose a unique interpretation of the sub-term !add(1, 2.5)! as it can very well be
evaluated to a value !4! of type !Int!, or a value !3.5! of type !Float!.
Haskell disallows such definitions with ambiguous types and reports a type error.
To resolve these type errors, the programmer needs to provide explicit type annotations
as hints to the type inference algorithm.

\section{Functional Dependencies}
\subsection{Examples}\label{subsec:fd}
\begin{figure}[ht]
  \footnotesize
  \begin{tabularx}\textwidth{X X}
\begin{code}^^J
class Addition m n p | m n -> p where^^J
\ \  add :: (m$\times$n) -> p^^J
^^J
instance Addition Int Float Int where -- Error!^^J
\ \  add(a,b) =\ $\ldots$^^J
\end{code}&%
\begin{code}^^J
instance Addition Int Float Float where^^J
\ \  add(a,b) =\ $\ldots$^^J
\end{code}
  \end{tabularx}
  \caption{\texttt{Addition m n p} with Functional Dependency and Conflicting Instances}
  \label{fig:add-tc-fd}
\end{figure}

%% How does this solve the previous problem
Typeclasses with functional dependencies\cite{jones_tcfd_2000} generalizes
multiparameter typeclasses. It introduces a new syntax for typeclass declarations
allowing users to specify a dependency between the type parameters.
The syntax for instance declarations does not change. !Addition m n p! typeclass,
as shown in \pref{fig:add-tc-fd}, has a functional dependency
between the type parameters such that types !m! and !n! determine the type !p!.
In other words, fixing the type !m! and !n! will also fix the type !p!.
In general we can have multiple parameters on both sides of the arrow,
(!$x_1$, ..., $x_m$ -> $y_1$, ..., $y_m$!). We write !X -> Y! to mean
``the parameters \texttt{X} uniquely determine the parameters \texttt{Y}''.

Functional dependencies aid the programmers to specify the intention of the typeclasses
more accurately and in turn gives the compiler a way to detect and report inconsistent instances.
For example, the functional dependency !m n -> p! on the type class !Addition m n p!,
helps the compiler flag the instance !Addition Int Float Int! to be in conflict with the instance
!Addition Int Float Float!.

An advantage of functional dependencies is that it can aid in determining
ambiguous type variables using an improvement technique.
Let's reconsider the ambiguous type of term !expr!
from the previous section, !(Addition Int Float b, Addition Float Int c) => c!. We can assert that !b!
has to be equal to !Float!, as it is determined by the types !Int! and !Float! using
the typeclass instance, !Addition Int Float Float!.
Thus, !expr! no longer has an ambiguous type, as it is inferred as !Addition Float Int c => c!.
We can go a step further, and improve this seemingly polymorphic type as well.
The type variable !c! can be determined to be !Float!, giving us the type of
!expr! to be !Float!. It would be impossible to make such
an improvement without the functional dependency on the typeclass.
\begin{figure}[ht]
  \footnotesize
  \begin{tabularx}\textwidth{X X}
\begin{code}^^J
data Z\ \ \ \ -- 0^^J
data S n\ \ -- 1 + n^^J
^^J
class IsPeano p^^J
instance IsPeano Z^^J
instance IsPeano n => IsPeano (S n)^^J
^^J
class Plus m n p | m n -> p^^J
instance IsPeano m => Plus Z m m^^J
instance Plus n m p => Plus (S n) m (S p)^^J
\end{code}&
\begin{code}^^J
data Vector s e = Vec ([e])^^J
^^J
concat_vec :: Plus m n p^^J
\ \ \ \ \ \ \ \ \ \ \ => Vector m e^^J
\ \ \ \ \ \ \ \ \ \ \ -> Vector n e^^J
\ \ \ \ \ \ \ \ \ \ \ -> Vector p e^^J
concat_vec (Vec l1) (Vec l2)^^J
\ \ \ \ \  = Vec (l1 ++ l2)^^J
\end{code}
  \end{tabularx}
  \caption{Peano Arithmetic and Vector Concatenation}
  \label{fig:peano-arith-tcfd}
\end{figure}

We can also perform Peano arithmetic at type level using functional dependencies,
as shown in \pref{fig:peano-arith-tcfd}. The two datatypes !Z! and !S n!
represent the number zero and successor of a number !n!, respectively at type level.
The instances of !IsPeano p! assert that: !Z! is a Peano number, and if !n! is a Peano number
then !S n! is a Peano number. The intention of !Plus m n p! typeclass is to build a relation such that
the addition of first two type parameters is equal to the third. The instances of !Plus m n p!
type class represent the axioms of Peano arithmetic: !Plus Z m m! represents the
axiom $0 + m = m$, and !Plus n m p => Plus (S n) m (S p)! represents the axiom,
if $n + m = p$ then $(1 + n) + m = (1 + p)$ at type level. The functional dependency !m n -> p!
plays an important role here: it ensures the result of addition of two numbers is a unique number.
The !concat_vec! function demonstrates why such type level computations might be useful
for a linear algebra library. The type of !concat_vec! says that the size of the resulting
vector is the sum of the sizes of the argument vectors. % This makes storing of the vector size
% in the representation superfluous, while guaranteeing type safety.
The above examples demonstrate how functional dependencies help in encoding
type level functions. The vanilla multiparameter typeclasses lacked
the capability of restricting the relation on types that is sometimes necessary to accurately
represent the programmers intention.

\subsection{Formalizing Typeclasses with Functional Dependencies}\label{subsec:tc-formal}
\begin{figure}[ht]
    \small
  \[
  \begin{array}{l l l}
    &\text{Type Variables}     &\alpha, \beta\\
    &\text{Term Variables}     &x, y\\
    &\text{Class Constructors} &\ClassCtrs\\
    &\text{Type Constants}  &\TypeCtrs\\    
    \\
    &\text{Term Typing}        &\QTyping \Preds \TEnv \Tm \tau\\
  \end{array}
  \begin{array}{l l l l}
    &\text{Class Predicates}      &\pi               &\bnfeq C\many{\tau}\\
    &\text{Predicate Set}         &\Preds,\MorePreds &\bnfeq \many\pi\\
    &\text{Types}                 &\tau              &\bnfeq \alpha \bnfor \tau\to\tau \bnfor \TypeCtrs\\
    &\text{Qualified Types}       &\rho              &\bnfeq \tau \bnfor \Preds\then\rho\\
    &\text{Type Schemes}          &\sigma            &\bnfeq \forall{\many\alpha}.\rho\\
    &\text{Terms}                 &\Tm               &\bnfeq x \bnfor \Tm\App\Tm \bnfor \Lam x \Tm\\
    % &\text{Values}          &\val              &\bnfeq \Lam x \tau \Tm
    \\
    &\text{Typing Environment} &\TEnv &\bnfeq \empt \bnfor \TEnv,x\co\sigma
  \end{array}
  \]
  \caption[\TCFD]{\TCFD}
  \label{fig:tcfd-syntax}
\end{figure}
% \TODO{start here. Why do we need to formalize? how should incoherence/ambiguity be formalized? How does functional
%   dependency prevent that?}
In the previous section, we made a case for why ambiguous types are problematic and how
functional dependencies can help us solve it. We now formalize this intuition to make our claim precise.
We organize the language as shown in \pref{fig:tcfd-syntax}, and call it \TCFD.
The types ($\tau$) can be type variables ($\alpha$), function types ($\tau\to\tau$), o
r type constants ($\TypeCtrs$), such as !Int!, !Float! etc. The qualified types ($\rho$) have the form $\Preds\then\rho$
where the predicate set, $\Preds$, constrains the type $\rho$.
Type schemes ($\sigma$) are quantified constraint types. The terms in the language ($\Tm$) are term variables ($x, y$),
functions ($\Lam x e$), where $x$ is the argument to the function body $e$,
and function applications ($e_1\App e_2$), which represents calling a function $e_1$ with an argument $e_2$.

% \subsubsection {Notations}\label{subsubsec:tcfd-notations}
% We will use the following notations. Subscripts on objects
% ($\alpha_1,\ldots, \alpha_n$) are used to distinguish them.
% A collection of items, $\Set{\alpha_1, \alpha_2, ..., \alpha_n}$,
% of arbitrary length is written as $\many\alpha$.
% % We use $S_1 \setdiff S_2$ to denote the set difference operation.
% For an object $X$, $\TV{X}$ is the set of type variables that are free in $X$.
% We write $[\many{x}\mapsto\many{y}]X$ to denote the substitution where each variable
% $x_i$ is mapped to $y_i$ in the object $X$. We also write $\Subst X$ for a substitution $\Subst$
% applied to $X$. We denote the most general unifier
% for two types $\tau_1$ and $\tau_2$ by $\mgu{\tau_1}{\tau_2}$\cite{robinson_machine-oriented_1965}.
% We assert non-existence of such a unifier by writing $\lnot\mgu{\tau_1}{\tau_2}$.
% We write $\mgu{\many{\tau_1}}{\many{\tau_2}}$ to give us a composition of most general
% unifier for each pair of types $(\tau_{1i}, \tau_{2i})$.
% We abbreviate the $\ClassCtrs\many\alpha$ as $\Preds$ and $\MorePreds$

We write !class $\Preds$ => $\ClassCtrs$ t! for a typeclass declaration,
where !t! are the type parameters of the class and $\Preds$
are the constraints that the type parameters additionally should satisfy.
For an instance of typeclass $\ClassCtrs$, we write !instance $\Preds$ => $\ClassCtrs$ t!,
where length of !t! matches the typeclass arity and additional constraints given by $\Preds$ on !t!
need to be satisfied. We denote the set of functional dependencies of class !C! with $\FunDep{C}$.
For an arbitrary functional dependency !$X$ -> $Y$!, the determinant of a functional dependency
is denoted by $t_{X}$, and the dependent by $t_{Y}$.
Given a set of functional dependencies $\texttt{F}$, we define the closure operation,
$\closure Z {\texttt{F}}$, on $Z \subseteq t$, to be equal to all the type parameters
that are determined by the functional dependencies in \texttt{F}.

For example, for a typeclass declaration !class Addition m n p | m n -> p!,
we have, $t = (m, n, p)$, $\FunDep{Addition}=$!$\{$ m n -> p $\}$!.
For the functional dependency !m n -> p!, we have, $t_X = {(\texttt{m},\texttt{n})}$ and $t_Y = {(\texttt{p})}$,
and $\closure {\Set{m}} {\FunDep{Add}} = \Set{m}$ and $\closure {\Set{m, n}} {\FunDep{Add}} = \Set{m, n, p}$.

The type environment, $\TEnv$, is a mapping between term variables to types
such that any term variable appears at most once. We write $\dom{\TEnv}$ to mean
the set of all term variables in $\TEnv$, or $\dom\TEnv = \Set{x \mid (x\co\tau) \in \TEnv}$.
We denote $\TEnv_x$ to be $\TEnv$ obtained after removing the binding for $x$ in $\TEnv$.
The typing judgments are of the form $\QTyping \Preds \TEnv \Tm \sigma$.
They assert existence of a typing derivation that shows the term $\Tm$, has the type $\sigma$,
satisfying the predicates $\Preds$, and the free term variables in $\Tm$
are assigned types by the typing environment $\TEnv$.
The typing rules that build the typing derivations in \TCFD are summarized
in \pref{fig:tcfd-typing}. In their present form, they do not use the functional dependencies.
\newcommand\TPAbs{
  \ib{\irule[\trule{$\I\then$}]
    {\QTyping {\Preds,\MorePreds} \TEnv \Tm \rho};
    {\QTyping \Preds \TEnv \Tm {\MorePreds\then\rho}}}
}

\newcommand\TPApp{
  \ib{\irule[\trule{$\E\then$}]
    {\QTyping \Preds \TEnv \Tm {\MorePreds\then\rho}}
    {\ent \Preds \MorePreds};
    {\QTyping \Preds \TEnv \Tm \rho}}
}

\newcommand\TAbs{
  \ib{\irule[\trule{$\I\to$}]
    {\QTyping \Preds {\TEnv_x, x\co\tau_1} {\Tm} {\tau_2}};
    {\QTyping \Preds \TEnv {\Lam x \Tm} {\tau_1 \to \tau_2}}}
}
 
\newcommand\TApp{
  \ib{\irule[\trule{$\E\to$}]
    {\QTyping \Preds \TEnv {\Tm_1} {\tau_2 \to \tau}}
    {\QTyping \Preds \TEnv {\Tm_2} {\tau_2}};
    {\QTyping \Preds \TEnv {\Tm_1\App\Tm_2} {\tau}}}
}

\newcommand\TVar{
  \ib{\irule[\trule{var}]
    {x\co\sigma \in \TEnv};
    {\QTyping {\Preds} {\TEnv} {x} {\sigma}}}
}

\newcommand\TForallI{
  \ib{\irule[\trule{$\I\forall$}]
    {\QTyping \Preds \TEnv \Tm \rho}
    {\alpha\not\in\TV\TEnv \cup \TV\Preds};
    {\QTyping \Preds \TEnv \Tm {\Forall{\alpha}\rho}}
  }
}

\newcommand\TForallE{
  \ib{\irule[\trule{$\E\forall$}]
    {\QTyping \Preds \TEnv \Tm {\Forall\alpha\rho}}
    {\beta~\text{fresh}};
    {\QTyping \Preds \TEnv \Tm {[\alpha\mapsto\beta]\rho}}
  }
}

\begin{figure}[ht]
  \centering
  \small
  \[
    \begin{array}{c}
      \TVar \\
      \TAbs \\
      \TApp \\          
    \end{array}
    \begin{array}{c}
      \TForallI\\
      \TForallE\\
      \TPAbs\\   
      \TPApp\\   
    \end{array}
  \]
  \caption{Typing judgments for \TCFD{} Terms}
  \label{fig:tcfd-typing}
\end{figure}

The left column lists the term typing rules that do not interact with predicates.
Each term structure has a typing rule specifying conditions that make the term well typed.
The rule \trule{var} says that if the variable $x$ has type $\sigma$ then
typing environment $\TEnv$ should contain the binding $x\co\sigma$.
The rule \trule{$\I\to$} says that if a term, $\Tm$, has type $\tau_2$
with a free variable $x$ of type $\tau_1$ then the term $\Lam x \Tm$
has a type $\tau_1 \to \tau_2$. The rule \trule{$\E\to$}
that says if a term (function) $\Tm_1$ is of type $\tau_2 \to \tau$
and another term (argument) $\Tm_2$ is of type $\tau_2$, then the term $\Tm_1\App\Tm_2$ is of type $\tau$.

The right column lists typing rules that involve the predicate set.
The rule \trule{$\I\forall$} generalizes the type. We use $\TV{X}$ to denote the set of
free type variables in object $X$. The rule \trule{$\E\forall$} instantiates the type.
It is necessary for $\beta$ to be a fresh type variable to ensure it does not conflict with
the existing free type variables. We write $[x \mapsto y]X$ to denote a substitution
where the variable $x$ in the object $X$ is mapped to $y$.
The rule \trule{$\I\then$} moves the global predicate $\MorePreds$
in to constrain the type $\rho$ while the \trule{$\E\then$} moves the constraint
out of the type $\rho$. The condition $\Preds\entails\MorePreds$,
read as ``$\Preds$ entails $\MorePreds$'', means that
whenever $\MorePreds$ is satisfied $\Preds$ is also satisfied.
The theory of qualified types\cite{jones_qualified_1994} mandates the entailment relation to
satisfy the three following properties:
\begin{enumerate}
\item Reflexivity: $\Preds\entails\Preds$
\item Transitivity: if $\Preds\entails\MorePreds_1$ and $\MorePreds_1\entails\MorePreds_2$
  then $\Preds\entails\MorePreds_2$
\item Regularity: if $\Preds\entails\MorePreds$ then $\Subst\Preds\entails\Subst\MorePreds$
\end{enumerate}
In the case of typeclasses, a predicate $\pi$ is of the form $\ClassCtrs\many\tau$, and it is satisfied
when we can find a typeclass instance that matches $\pi$.
The above three properties indeed hold for the \TCFD's formulation of predicate satisfiability.
The typing rules that we just discussed do not use any functional dependencies induced by the predicates.
The use of the rules \trule{$\I\then$} followed by \trule{$\I\forall$} in the typing derivation can introduce
ambiguous types.
% We need to have an extra rule that lets us use the predicates to determine
% the seemingly free type variables.

\subsection{Ambiguous Types and Improving Substitution}\label{subsec:fd-improve}
The usual ambiguity check, for a qualified type, $\forall\many{\alpha}.\Preds\then\tau$,
is to ensure that all quantified type variables in the predicates $\Preds$ also appear in the type $\tau$,
or $(\many{\alpha}\cap\TV{P}) \subseteq \TV{\tau}$. 
With induced functional dependencies, $\FunDep P$, due to $\Preds$,
the appropriate check would be $(\many{\alpha}\cap\TV{P})
\subseteq \closure {\TV{\tau}} {\FunDep \Preds}$. We weaken the check
as there may be some free type variables that can be determined
using the induced functional dependencies by the constraint set $\Preds$.
For example, the type of !expr! will no longer be flagged as ambiguous as
the type variable !b! in !(Addition Int Float b, Addition b Int c) => c! is actually
determined using the functional dependency !m n -> p!.
% An improving substitution can very well be a trivial identity substitution
% when there are no type variables to improve on.
% Computing it may also fail which would mean that we have a predicate
% set that is unsatisfiable and the term can be flagged as an illtyped term.

% The typing rules shown in \pref{fig:tcfd-typing} does not included the use of functional dependencies.
% We will now formalize it using an extra typing rule \trule{impr} that we motivate below.

Further, we may also want to show what the concise type is for a term is.
This enhances usability of the system as the programmer would prefer the type of !expr!
to be shown as !Float! rather than the above inferred type !(Add Int Float b, Add b Int c) => c!.
We need to have an extra component in the type inference that lets us use
the functional dependencies to determine the seemingly free type variables.
An improving substitution, written as $\impr{\Preds}$, is a substitution that does
not change the set of satisfiable instances of predicate set $\Preds$. 
The rational behind improving substitution is that it helps simplify
the type by showing its true and concise characterization.
In \TCFD, computing an improving substitution is to find if any type variables
can be determined using the functional dependencies induced by the predicate set.
%We write $\Subst X$ to mean the substitution, $\Subst$, is applied to object $X$.
For each functional dependency !X->Y!, induced by a class constraint !C t! in the predicate set $\Preds$,
whenever we know $\TV{t_X}$, then we can determine $\TV{t_Y}$.
% The notation $\rho_\MorePreds$ stands for the predicate set $\MorePreds$ that constrains the
% qualified type $\rho$, of the form $\MorePreds\then\tau$.
For example, in case of !expr!, where we inferred the most general type to be
!(Addition Int Float b, Addition b Float c) => c!,
the improvement substitution, $[b\mapsto\texttt{Float}, c\mapsto\texttt{Float}]$,
obtained by using the functional dependency, $\FunDep {Add} = \Set{\texttt{m n} \to \texttt{p}}$,
gives us the improved type !Float!.


%% How can one detect inconsistent class instances in the formalization
\subsection{Instance Validity and Inconsistency Detection}
Every typeclass introduces a new relation on types. Functional dependencies give
additional conditions that every instance should satisfy so that the
instances declared are compatible with each other. There are two necessary conditions to ensure this:
\begin{enumerate}[topsep={0pt},partopsep={0pt}]
\item\emph{Covering Condition}:  For each new instance declaration !instance $\Preds$ => C t where ...!
  that the programmer writes, we need to check that for each functional dependency of the form $(X \to Y) \in \FunDep{P,C}$,
  $\TV{t_Y} \subseteq \closure{\TV{t_X}}{\FunDep{P,C}}$.
  $\FunDep{P,C}$ are the functional dependencies induced by the class $C$ and additional dependencies
  induced by the instance context $P$. Intuitively, this condition says that
  all the type variables in the dependent parameter, $\TV{t_Y}$, of a functional dependency $(X \to Y) \in \FunDep{P,C}$,
  should either already be in the set of determinant type variables, $\TV{t_X}$,
  or they should be fully determined using the
  functional dependencies induced by the class $\ClassCtrs$, or those that are
  induced by the instance constraints $\Preds$.

  For example, for a typeclass declaration
  !class C a b |  a -> b!, the instance declaration !instance C Int a! fails the coverage test,
  while !instance C a Int! passes it.
\item\emph{Consistency Condition}: For each pair of instance of the form !instance $\MorePreds$ => C s where ...!
  and !instance $\Preds$ => C t where ...! we need to ensure whenever $t_Y = s_Y$ we also have $t_X = s_X$.
  It is straightforward to check this condition. We first find the most general unifier for $t_X$ and $s_X$,
  say $U=\mgu {t_X}{s_X} $, and then check that $U t_Y = U s_Y$. If we cannot find such a unifier, then we know that
  the instances are consistent. The most general unifier, $\mgu{\tau_1, \tau_2}$, can be computed using
  Robinson's algorithm\cite{robinson_machine-oriented_1965}.

  For example, !instance C Int [Int]! is consistent with !instance C Char [Char]!
  as there is no unifier for !Int! and !Char!. However, !instance C a Int! together with
  !instance C a Float! fails the consistency condition.% with an identity unifier.
\end{enumerate}

\section{Associated Types}\label{sec:assoc-types}
Another way to express type computation is by having the typeclass with
an associated type\cite{chakravarty_associated_2005}.
In this style, each instance of the typeclass specifies how the associated type should be represented.
For example, !Addition m n p! typeclass can be written using an associated type as shown in \pref{fig:add-assoc-type}.
\begin{figure}[ht]\centering
  \footnotesize
  \begin{tabularx}\textwidth{X X}
\begin{code}^^J
class Addition m n where^^J
\ \ type Result m n^^J
\ \ add :: (m$\times$n) -> Result m n^^J
^^J
instance Addition Float Float where^^J
\ \ type Result Float Float = Float^^J
\ \ add(f, f) = $\ldots$^^J
^^J
instance Addition Int Float where -- Error^^J
\ \  add(i, f) = primAddI(i, (truncFtoI f))^^J
\end{code}&%
\begin{code}^^J
instance Addition Int Float where^^J
\ \  type Result Int Float = Float^^J
\ \  add(i, f) = $\ldots$^^J
^^J
instance Addition Float Int where^^J
\ \  type Result Float Int  = Float^^J
\ \  add(f, i) = $\ldots$
\end{code}
  \end{tabularx}
  \caption{\texttt{Addition m n} typeclass with an Associated Type \texttt{Result m n}}
  \label{fig:add-assoc-type}
\end{figure}

The typeclass !Addition m n! has two type parameters in this style.
The type of !add! changes slightly: it returns a value of type !Result m n!.
The !Result m n! associated type can be thought of as a placeholder type
that gets reduced to the representation type during the type analysis phase
once the type parameters !m! and !n! are specified. The logic
of reduction is given in each typeclass instance declaration using type equations.
This effectively solves the problem of ambiguous types; the instantiation
of !Result m n! reduces to a specific type. The type of the subterm !(add (1, 2.5))!
in !expr! will now be inferred as !Float!, as
!Result Int Float! reduces to !Float!. The associated type
it can be thought as a type function in a way; depending on its use context,
it reduces to an appropriate representation type.
% The attractiveness of this style is that
% we have a straightforward reading of type functions.

% The type !Plus m n! has two representations due to the two typeclass instances,
% !Plus Z n  = Z! represents the axiom $0 + n = 0$,
% while !Plus (S m) n = S (Plus m n)! represents the axiom, if $(1 + m) + n$ then $1 + (m + n)$.


% The type of !concat_vec! changes as !Plus n m! is now treated as a type
% and it does not have a relational style reading. As visible from the code snippet,
% attractiveness of this style is that type computation is
% no longer limited in the predicates.

\begin{figure}[ht]
  \begin{tabularx}{\textwidth}{X X} 
\begin{code}^^J
class Tricky a where^^J
\ \ type Trick a^^J
^^J
instance Tricky Bool where^^J
\ \ type Trick Bool = Int -> Int^^J
^^J
instance Tricky a where^^J
\ \ type Trick a    = Bool^^J
\end{code}&
\begin{code}^^J
funTrick :: a -> Trick a^^J
funTrick _ = True^^J
^^J
$\text{\faBomb}$ :: Int^^J 
$\text{\faBomb}$ = funTrick True 5^^J
\end{code}
\end{tabularx}  
  \caption{\texttt{Tricky a} Typeclass and Type Inconsistency}
  \label{fig:tricky-assoc-type}
\end{figure}

% An enthusiastic programmer might now try write a type function for computing type equality
% using a typeclass !TEqC a b! with an associated type !TEq a b! as shown below.
% We use !TT! and !FF! to represent type level true and false respectively.
% The associated type !TEq a b! computes if the two types !a! and !b! are equal buy
% returning !TT! if it is instantiated by the same types, !FF! otherwise.

% {\footnotesize\centering
%   \begin{tabularx}\textwidth{X X X}
% % \begin{code}^^J
% % data TT -- True^^J
% % data FF -- False^^J
% % \end{code}&%
% \begin{code}^^J
% class TEqC a b where^^J
% \ \ type TEq a b^^J
% \end{code}&%
% \begin{code}^^J
% instance TEqC a a where^^J
% \ \ type TEq a a = TT^^J
% \end{code}&%
% \begin{code}^^J
% instance TEqC a b where -- Error^^J
% \ \ type TEq a b = FF^^J
% \end{code}
%   \end{tabularx}
% }\\
Now suppose, a programmer writes a !Tricky a! typeclass shown in \pref{fig:tricky-assoc-type}.
It has two instances where, !Trick Bool! reduces to a function type !Int -> Int!, and !Trick a! reduces to !Bool!.
Next, consider the function !funTrick!. The type !Trick a!, reduces to !Bool! matching
the instance !Tricky a!. The use of !funTrick! in \faBomb, however, instantiates
the !funTrick! to type !Trick Bool!, and !Trick Bool!, in turn, reduces to !Int -> Int!.
The type analysis finds no type errors. At runtime, the value returned by !funTrick! is !True!,
and !True 5! crashes the program.

Haskell rejects such programs as it can cause type inconsistency as described above.
The check that Haskell uses is that of overlapping instances; !Tricky a! and !Tricky Bool! overlap.
The intention of the programmer was to be able to reduce !Tricky a! to !Int -> Int!
when !a! is !Bool!, and reduce it to !Bool! in all other cases. However, there is no way for the compiler
to know this, and there is no language construct that supports such type reductions.

% The check that is uses
% is that of overlapping instances as !Tricky Bool! and !Tricky a! are overlapping.

% To the programmers disappointment, this definition is rejected by the type system.
% The presence of both instances !Tricky Bool! and !Tricky a! is conflicting due to their overlap.
% Haskell rejects overlapping instances as they can introduce type inconsistency in the system.
% For example, in
% Two instances overlap when both instances provide a match while resolving a constraint.
% For example, both the instances !TEqC a a! and !TEqC a b! can be used to match the constraint
% !TEqC Int Int!. There is no way for the compiler to choose one instance over the other.
% Haskell rejects programs that have overlapping instances. %as it assumes
%that there can only be a unique typeclass instance that matches the constraint.

\section{Closed Type Families}\label{sec:tf-closed}
\subsection{Examples}
Closed type families is a generalization of associated typeclasses. We notice from
the above !Tricky a! typeclass example that we could separate out the associated type !Trick a!
into its own entity and collect each of its type equations defined in the instances in one place as shown below.
\begin{figure}[ht]
  \centering
  \begin{tabularx}{\textwidth/2}{X}
\begin{code}^^J
type family Tricky a where^^J
\ \ Trick Bool = Int -> Int^^J
\ \ Trick a    = Bool^^J
\end{code}
  \end{tabularx}
\end{figure}

% {\footnotesize
% \begin{tabularx}\textwidth{X}
% \begin{code}^^J
% type family Plus n m where^^J
% \ \ Plus Z     m = m  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ -- 0 + m = m^^J
% \ \ Plus (S n) m = S (Plus n m) \ \ \ -- (1 + n) + m => 1 + (m + n) ^^J
% \end{code}
% \end{tabularx}
% }
One can think of a type family to be a family of types indexed its type parameters.
In this case, the type family !Tricky a! has one type parameter, !a!, that it is indexed by.
Each equation specifies what the type reduces to for specific type parameters; !Tricky Bool = Int -> Int! means
that !Tricky Bool! will reduce to !Int -> Int!. This style of writing type functions is more palatable
for functional programmers. It resembles a familiar style of writing term level equations with pattern matching.
\begin{figure}[ht]
\centering\small
\begin{tabularx}{\textwidth}{X X}
\begin{code}^^J
type family Result m n where^^J
\ \  Result a   a = a^^J
\ \  Result a   Float = Float^^J
\ \  Result Float a = Float^^J
^^J
class Addition m n where^^J
\ \  add :: (m$\times$n) -> Result m n^^J
^^J
instance Addition Float Float where^^J
\ \  add(f1, f2) =\ $\ldots$^^J
\end{code}&%
\begin{code}^^J
instance Addition Int Float where^^J
\ \  add(i, f) =\ $\ldots$^^J
^^J
instance Addition Float Int where^^J
\ \  add(f,i) =\ $\ldots$^^J
^^J
instance Addition Int Int where^^J
\ \  add(i1, i2) =\ $\ldots$^^J
\end{code}
\end{tabularx}
\caption{\texttt{Add} Typeclass using \texttt{Result} Closed Type Family}
\label{fig:add-ty-fam}
\end{figure}

The !Addition m n! typeclass, defined using an associated type in \pref{fig:add-assoc-type},
can also be written in a closed type family style as shown in \pref{fig:add-ty-fam}.
The type equations written in the instances now move into a closed type family declaration !Result m n!.
% The compiler rejects the instance !Addition Int Float! where the !add! function returns
% and !Int! instead of !Float! as the type family equation 
The advantage of closed type families over associated types,
is the ability to express type functions that were previously not possible
such as !Result a a = a! or in case of !Tricky a! type family, !Tricky a = Bool!.
Fixing the order of equation matching liberates us from the restriction
of allowing only non-overlapping type equations;
the first equation will match the type !Result Int Int! and reduce it to !Int!.
As another example, previously shown Peano arithmetic using functional dependency style,
is now shown using closed type family in \pref{fig:peano-arith-ctf}. The first equation encodes the axiom
$0 + n = n$, while the second equation encodes the axiom, $(1 + n) + m = 1 + (n + m)$.
As a cherry on top, the second equation computes the addition of two type level Peano numbers using recursion,
which functional programmers adore.
\begin{figure}[ht]
  \centering
  \begin{tabularx}{\textwidth/2}{X}
\begin{code}^^J
type family Plus m n where^^J
\ \ Plus Z n = n \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  -- 0 + n = n^^J
\ \ Plus (S n) m = S (Plus n m) -- (1 + n) + m = 1 + (n + m)^^J
\end{code}
  \end{tabularx}
  \caption[Peano Arithmetic]{Peano Arithmetic using Closed Type Family}
  \label{fig:peano-arith-ctf}
\end{figure}

% We will write $\stepsto{\tau_1}{\tau_2}$ to mean
% the type $\tau_1$ reduces to $\tau_2$, for example, !Result Int Float $\rightsquigarrow$ Float!
\subsection{Type Matching, Apartness and Reduction}\label{subsec:tf-closed-apartness}
The role of type families is to compute, or reduce to, the representation
the using instantiations type indices during the type analysis phase. For example, the representation
type of !Result Int Float! is !Float! while, the representation type of !Plus Z n! is !n!.
The semantics of such equations have subtleties. The reduction of an
occurrence of a type family type is done using a top to bottom matching technique.
The first equation that matches is used for reduction. For example, to reduce type !Addition Float Float!,
first equation !Addition a a = a! matches it and reduces it to !Float!.

\begin{figure}[ht]
  \small
  \begin{tabularx}\textwidth{X X X} 
\begin{code}^^J
type family Tricky a where^^J
\ \ Tricky Bool = Int -> Int^^J
\ \ Tricky a    = Bool^^J
\end{code}&
\begin{code}^^J
funTrick :: a -> Tricky a^^J
funTrick _ = True^^J
\end{code}&
\begin{code}^^J
$\text{\faBomb}$ :: Int^^J 
$\text{\faBomb}$ = funTrick True 5^^J
\end{code}
\end{tabularx}
  \caption{Inconsistency due to Tricky Type Family}
  \label{fig:closed-tf-tricky}
\end{figure}

Now, let us reconsider the function !funTrick! and the closed type family !Tricky a!, shown in \pref{fig:closed-tf-tricky}.
The type !Tricky a! does not match the first equation but matches the second equation and reduces to !Bool!.
This reduction, however, will crash the program, !$\text{\faBomb}$!, which uses !funTrick!
and instantiates !d! to !Bool!, and !Tricky Bool! in turn reduces to !Int -> Int!.
Type inconsistency bugs can be introduced if a na\"ive type reduction strategy
is used with overlapping equations. We need to identify a reduction strategy that does not violate type consistency.

Fortunately, having a confluent type reduction relation is not only a necessary but also a sufficient condition
to achieve type consistency\cite{bezem_term_2003}. If a type has multiple ways of reducing,
it should not matter what way we choose, the final type obtained should always the same. %apologies to robert frost.
In the above example, we did see a consequence of non-confluence; one way of reduction
gave us !Int -> Int! while the the other, gave us !Bool!, resulting in a runtime crash.
We fix this behavior by incorporating flattening and apartness into the type reduction strategy.
First we define the notion of matching:
%% Motivate type flattening for matching
\begin{defn}[Matching, $\match \tau \sigma$]\label{def:ctf-match}
  We say a type $\tau$ matches $\sigma$, if and only if there is a substitution
  $\Subst$ such that, $\dom\Subst \subseteq \TV\tau$ and $\Subst\tau = \sigma$.
\end{defn}

\begin{defn}[Type Flattening, $\flatten\tau$]\label{def:ctf-flatten}
  We say a type $\tau$ is flattened to $\tau_1$, when every
  type family application of the form $\FamCtrs(\many\sigma)$ in $\tau$
  is replaced by a type variable, such that in the flattened type,
  all syntactically equivalent type family applications
  are replaced by a same type variable, and syntactically different
  type family applications are replaced by distinct fresh type variables.
\end{defn}
\begin{defn}[Apartness, $\apart p \tau$]\label{def:ctf-apart}
  For an equation, $p$, and a type, $\tau$, $p$ is apart from $\tau$, if
  and only if we cannot unify the left hand side of the equation and the flattened $\tau$.
\end{defn}
Finally, the equation selection criterion for type reduction strategy can be defined as follows:
\begin{defn}[\CLTF Type Reduction Strategy]\label{def:ctf-simpl-1}
  An equation, $p$, given in the type family declaration of $\FamCtrs$, can be used to simplify the type
  $\FamCtrs(\many\tau)$, if the two following conditions hold:
  \begin{enumerate}
  \item The left hand side of the equation matches the type $\FamCtrs(\many\tau)$.
  \item All equations that precede $p$, are apart from $\FamCtrs(\many\tau)$.
  \end{enumerate}
\end{defn}
Let us reconsider the type !a -> Tricky a!, with the above definition of type family reduction.
Now, !Tricky Bool! does not match !Tricky a!, as there is no substitution,
$\Subst$, such that $\Subst\texttt{Bool} = \texttt{Int}$.
However, !Tricky Bool! is not apart from !Tricky d!---the substitution $[d\mapsto\texttt{Bool}]$ does unify them,
hence we cannot use the second equation for type reduction; doing so will violate
the second criterion from \pref{def:ctf-simpl-1}.

% \begin{figure}[ht]
%   \centering\small
%   \begin{tabularx}\textwidth{X X X}
% \begin{code}^^J
% type family G a b where^^J
% \ \ G Int Bool = Int^^J
% \ \ G a   a    = Bool^^J
% \end{code}&
% \begin{code}^^J
% type family F a where^^J
% \ \ F Int    = Char^^J
% \ \ F a      = Bool^^J
% \end{code}&
% \begin{code}^^J
% G (F a) (F a)\ $\mathrel{\rightsquigarrow}$ Bool^^J
% G (F a) (F b)\ $\mathrel{\not\rightsquigarrow}$ Bool^^J
% \end{code}
%   \end{tabularx}
%   \caption{Type family Reduction requires Type Flattening}
%   \label{fig:ctf-red-ex}
% \end{figure}

Type flattening with sharing optimizes the type reduction process in some cases.
For example, consider the type: !Result (Result c d) (Result c d)!.
We cannot reduce this type without flattening. However, with flattening,
this type is transformed to !Result b b!, which matches the first equation, !Result a a = a!,
and we can reduce the original type to !Result c d!.
However, if we did not have sharing, we would flatten it to !Result a b!,
and we would can no longer be able to use the first equation for reduction.

Reduction of type families by apartness check will ensure consistency
but it has two shortcomings: 1) it is overly restrictive, and
2) it is inefficient due to the excessive calls to unification.
We will illustrate them by using a couple examples: Consider second and third equations from !Add! type family---
!Addition a Float = Float! and !Addition Float a = Float!---, and the type !Addition Float b!, which we wish to reduce.
In this case, reduction of !Addition Float b! to !Float! is not possible as the second equation is not apart
from !Addition Float b!. But we know that both the equations reduce to the same final type, which is !Float!.
We call such equations coincident equations. We would like to allow such reductions as they will not
threaten consistency. Next, consider the equations of the !Plus m n! type family, !Plus Z m! and !Plus (S n) m!.
It is easy to see that if any type matches !Plus (S m) m!, it will always be apart from !Plus Z m!, and
we can thus safely skip on the apartness check. We can overcome on both of these shortcomings by using the notion of compatibility
of equations defined below and incorporate it in our reduction strategy.
\begin{defn}[Compatible Equations, $\compat p q$]\label{def:compact-eqns}
  Two equations are compatible if and only if, whenever the left hand sides of the equations
  unify then so do the right hand sides of the equations. % exist two substitutions,
  % say $\Subst_p$ and $\Subst_q$, such that if their application to the left hand sides of the equations
  % equates them then the right hand sides after applying the respective substitutions also equates them.
  More formally, equations $p$ and $q$ are compatible if and only if whenever there exist substitutions
  $\Subst_p$ and $\Subst_q $ such that, if $\Subst_p(\lhs{p}) = \Subst_q(\lhs{q})$
  then $\Subst_p(\rhs{p}) = \Subst_p(\rhs{q})$.
\end{defn}
\begin{defn}[\CLTF Type Reduction Strategy Optimized]\label{def:ctf-simpl}
  An equation, say $p$, given in the type family declaration can be used to simplify the type
  $\FamCtrs(\many\tau)$, if the two following conditions hold:
  \begin{enumerate}
  \item The left hand side of the equation matches the the type $\FamCtrs(\many\tau)$
  \item All equations preceding $p$ are either compatible with $p$, or they are apart from $\FamCtrs(\many\tau)$.
  \end{enumerate}
\end{defn}
The two key insights here are that compatibility check loosens up the restriction
to enable type reductions without threatening consistency, and compatibility of equations
can be precomputed as it does not depend on the type we want to reduce
thus, effectively giving us a cheaper check as compared to the apartness check.

\subsection{Formalizing Type Reduction and Type Consistency}\label{subsec:tf-closed-formal}
In the previous section, we alluded that type consistency can be achieved using
confluence. In this section we will formalize it using \CLTF. The portion of the system necessary
to show type consistency is shown in \pref{fig:syntax-tf-closed}. We have special syntax category for
type family constructors ($\FamCtrs,\MoreFamCtrs$) along with the usual types.
A type pattern ($\FamPattern$) are tuple of types none of which contain type family constructors.
The size of the pattern is same as that of the type family constructor arity.
Predicates in this system are of the form $\tau_1\teq \tau_2$ and assert that types $\tau_1$ and $\tau_2$ are equal.
We also call them type equality predicates. The axioms, ($\Axiom\co\AxiomTy$),
are named list of type family equations that are declared with the type family constructors.
\begin{figure}[ht]
    \footnotesize
  \[
    \begin{array}{l l l}
      &\text{Type family Constructors} & \FamCtrs,\MoreFamCtrs\\
      &\text{Type Constants} &\texttt{\TypeCtrs}\\
      \\
      % &\text{Type Validity}               &\ValidType \TEnv \tau\\
      % &\text{Proposition Validity}        &\ValidProp \TEnv \pi\\
      % &\text{Ground Context Validity}     &\ValidGCtx{\GEnv}\\
      % &\text{Variable Context Validity}   &\ValidVCtx\GEnv\VEnv\\
      % &\text{Context Validity}            &\ValidCtx\TEnv\\
      \\
      &\text{Type reduction}              &\tystepsto\GEnv\bullet\bullet
      % \\
      % &\text{Term Typing}              &\Typing \TEnv \Tm \tau\\
      % &\text{Coercion Typing}          &\CoTyping \TEnv \Co \Preds\\
      \\
      &\text{One Hole Type Context}    &\TEvalCtxt{\bullet}
    \end{array}
    \begin{array}{l l l l l}
      &\text{Types}           &\tau,\sigma  &\bnfeq \alpha \bnfor \tau\to\tau %\bnfor \Forall\alpha\tau
                                              \bnfor \FamCtrs(\many\tau) \bnfor \TypeCtrs\\% 
      &\text{Value Types}    &\GTy         &\bnfeq \tau\to\tau \bnfor \TypeCtrs\\
      &\text{Type Equality Predicate}      &\pi          &\bnfeq \tau\teq\tau\\
      &\text{Predicates}     &\Preds       &\bnfeq \many\pi\\
      &\text{Type family Pattern}     &\texttt{\FamPattern} &\bnfeq \many{\alpha \bnfor \GTy}\\
      &\text{Axiom Equations} &\AxiomEq     &\bnfeq \Forall{\many\alpha}{\FamCtrs(\FamPattern) \teq \sigma}\\
      &\text{Axiom Types}     &\AxiomTy     &\bnfeq \many\AxiomEq\\
      % &\text{Coercions}  &\Co,\MoreCo &\bnfeq \Co\to\MoreCo \bnfor \Forall\alpha\Co \bnfor \Co@\tau
      %                                   \bnfor \FamCtrs(\many{\Co}) \bnfor\TypeCtrs(\many{\Co})\\
      % &                  &            &\bnfor \nth i \Co \bnfor \refl\tau \bnfor \sym{\Co} \bnfor \comp\Co\MoreCo
      %                                   \bnfor \branch{i}{\many\tau} & \\
      % \\
      % &\text{Terms}      & \Tm        &\bnfeq x \bnfor \Lam x \tau \Tm \bnfor \Tm\App\Tm \bnfor\cast M \Co 
      %                                   \bnfor \TLam \alpha \Tm \bnfor \Tm\App\tau  \\
      % &                  &            & \bnfor \DataCtrs\many{e} \\
      % &\text{Values}     &\Val        &\bnfeq \Lam x \tau \Tm \bnfor \DataCtrs\many\Tm \bnfor \TLam \alpha \Tm\\
      \\
      &\text{Ground Context} &\GEnv   &\bnfeq \empt \bnfor \GEnv,\Axiom:\AxiomTy
                                        %\bnfor \GEnv,\FamCtrs:n\\% \bnfor \GEnv,\TypeCtrs:n\\
      % &\text{Variable Context}&\VEnv  &\bnfeq \empt \bnfor \VEnv,x\co\tau \bnfor \VEnv,\alpha\\
      % &\text{Typing Context}  &\TEnv  &\bnfeq \GEnv;\VEnv\\
      % \\
      % &\text{Type family Declaration} & & \texttt{\textbf{type family}}~
      %                                     \FamCtrs\App\many{\alpha}\texttt{\textbf{ where }}
      %                                     \many{F\App\FamPattern = \tau}
    \end{array}
  \]
  \caption[Excerpt \CLTF{}]{Excerpt of System for Closed Type Families (\CLTF)}
  \label{fig:syntax-tf-closed}
\end{figure}
For example, the type family declaration for !Plus m n! type family will be represented as
$\texttt{AxPlus}: [\forall\alpha.~{\texttt{Plus}~Z~\alpha} \teq \alpha
, \forall\alpha\beta.~{\texttt{Plus}~(\texttt{S}~\alpha)~\beta} \teq \texttt{S}(\texttt{Plus}~\alpha~\beta)]$
We refer to the collection of all axioms as the ground context ($\GEnv$).

We formally state type reduction as follows:
\begin{defn}[Type Reduction: $\tystepsto\GEnv\bullet\bullet$, $\manytystepsto\GEnv\bullet\bullet$]
  \label{def:type-reduction}
  A type $\tau$ reduces to type $\sigma$, written $\tystepsto\GEnv{\tau}{\sigma}$,
  if we can build a predicates $\pi$, of the form $\tau\teq\sigma$, using the axioms in $\GEnv$.
  We define $\manytystepsto\GEnv\bullet\bullet$ to be a reflexive and transitive
  closure of $\tystepsto\GEnv\bullet\bullet$.
\end{defn}

\newcommand\NcApart{
  \ib{\irule[\trule{nc-apart}]
    {\AxiomTy = \many{\FamCtrs(\FamPattern) \teq \sigma}}
    {\apart{\FamPattern_j}{\FamPattern_i[\many\tau/\many\alpha_i]}};
    {\nc \AxiomTy i {\many\tau} j}}
}
\newcommand\NcCompt{
  \ib{\irule[\trule{nc-compt}]
    {\compat {\AxiomTy[i]}{\AxiomTy[j]}};
    {\nc \AxiomTy i {\many\tau} j}}
}
\newcommand\CompatInc{
  \ib{\irule[\trule{compt-inc}]
    {
      \begin{array}{@{}c@{}}
        {\AxiomEq_1 = \FamCtrs(\FamPattern_1) \teq \sigma_1}\\
        {\AxiomEq_2 = \FamCtrs(\FamPattern_2) \teq \sigma_2}
      \end{array}
    }
    {
      \begin{array}{@{}c@{}}
        {\Subst = \mgu{\FamPattern_1}{\FamPattern_2}} \\
        {\Subst\sigma_1 = \Subst\sigma_2}
      \end{array}
    };
    {\compat{\AxiomEq_1}{\AxiomEq_2}}}
}

\newcommand\CompatDist{
  \ib{\irule[\trule{compt-dis}]
    {
      \begin{array}{@{}c@{}}
        {\AxiomEq_1 = \FamCtrs(\FamPattern_1) \teq \sigma_1}\\
        {\AxiomEq_2 = \FamCtrs(\FamPattern_2) \teq \sigma_2}
      \end{array}
    }
    {\Subst = \mgu{\FamPattern_1}{\FamPattern_2}\fails};
    {\compat{\AxiomEq_1}{\AxiomEq_2}}}
}

\newcommand\TypeRed{
  \ib{\irule[\trule{ty-$\beta$}]
    {
      \begin{array}{c}
        {\AxiomTy = \many{\Forall{\many\alpha}\FamCtrs(\FamPattern) \teq \sigma}}\\
        {\Axiom\co\AxiomTy\in\GEnv}
      \end{array}
    }
    {\forall j < i. ~\nc \AxiomTy i {\many\tau} j}
    {
      \begin{array}{c}
        {\Subst=\mgu {N_i}{\many\tau}}\\
        {\tau_0 = \Subst\sigma_i}
      \end{array}
    };
    {\tystepsto \GEnv {\TEvalCtxt{\FamCtrs(\many\tau)}} {\TEvalCtxt{\tau_0}}} }
}

\begin{figure}[ht]
  \small
  \[
    \begin{array}{c c}
      \NcApart & \CompatDist\\
      \NcCompt & \CompatInc
    \end{array}
  \]
  \[
    \begin{array}{c}
      \TypeRed
    \end{array}
  \]  
  \caption{Non Conflicting Equations, Compatibility and Type Reduction}
  \label{fig:tf-closed-nc}
\end{figure}

We are essentially giving semantics to type reduction using type equality predicates.
The compiler has two main ways to generate equality predicates.
It can either find an appropriate axiom to instantiate from the ground context,
or it can use one of the following axioms: reflexivity ($\empt\entails\tau_1\teq\tau_1$),
symmetry ($\tau_1\teq\tau_2 \entails \tau_2\teq\tau_1$),
transitivity ($\tau_1\teq\tau_2, \tau_2\teq\tau_3\entails\tau_1\teq\tau_3$),
and congruence (($\tau_{11}\teq\tau_{12},\tau_{21}\teq\tau_{22})\entails(\tau_{11}\to\tau_{21})\teq(\tau_{12}\to\tau_{22})$).
These extra axioms are due to the fact that type equality forms an equivalence relation and a congruence relation.
The appropriateness of axioms is exactly what \pref{def:ctf-simpl} describes. We formalize the definition
in a rule format as shown in \pref{fig:tf-closed-nc}. The rule \trule{ty-$\beta$}
packages everything together. This rule says that the $i$-th equation of axiom $\Axiom$,
$\Forall{\many{\alpha_i}}{\FamCtrs(\FamPattern_i) \teq \sigma_i}$, is used to reduce
the target type $\FamCtrs(\many\tau)$ to type $\tau_0$.
The clause $\forall j < i. ~\nc \AxiomTy i {\many\tau} j$ ensures that we do not
perform unsound reductions. The $\TEvalCtxt\bullet$ says that the type reduction
can occur anywhere within the type structure. 

To get an idea of how these rules work out for the type reduction, let us consider the type !Plus (S Z) (Plus Z (S Z))!,
along with the axioms in \texttt{AxPlus}. First, we see that !Plus Z (S Z)! $\steps$ !S Z!,
as it matches the first equation, $\texttt{AxPlus}[1]$. Then, !Plus (S Z) (S Z)! reduces to !S (Plus Z (S Z))!
as it second equation matches the type and the first equation is compatible by being disjoint using
the rule \trule{compat-dis}. Finally, !S (Plus Z (S Z))! reduces to !S (S Z)!, giving us the expected result.
The predicates that we built in this process were: !Plus Z (S Z)! $\teq$ !S Z!,
!Plus (S Z) (S Z)! $\teq$ !S (Plus Z (S Z))!, !S (Plus Z (S Z)) $\teq$ S (S Z)!
and !Plus (S Z) (Plus Z (S Z)) $\teq$ S (S Z)!.

\newcommand\TCast{
  \ib{\irule[\trule{t-cast}]
    {\CoTyping \TEnv \Co {\tau_1\teq\tau_2}}
    {\Typing \TEnv \Tm \tau_1};
    {\Typing \TEnv \Tm \tau_2}}}

\newcommand\TTyAbs{
  \ib{\irule[\trule{t-tyabs}]
    {\ValidType \TEnv \alpha}
    {\Typing {\TEnv,\alpha} \Tm \tau};
    {\Typing \TEnv {\TLam\alpha\Tm} {\Forall\alpha\tau}}}}

\newcommand\TTyApp{
  \ib{\irule[\trule{t-tyapp}]
    {\ValidType \TEnv {\tau_1}}
    {\Typing \TEnv \Tm {\Forall\alpha\tau}};
    {\Typing \TEnv {\Tm\App\tau_1} \tau[\tau_1/\alpha]}}}


\newcommand\CoArr{
  \ib{\irule[\trule{co-arr}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \sigma_1}}
    {\CoTyping \TEnv \MoreCo {\tau_2 \teq \sigma_2}};
    {\CoTyping \TEnv {\Co\to\MoreCo} {(\tau_1\to\tau_2) \teq (\sigma_1\to\sigma_2)}}}}

\newcommand\CoNthArr{
  \ib{\irule[\trule{co-ntharr$_i$}]
    {\CoTyping \TEnv \Co {(\tau_1\to\tau_2) \teq (\sigma_1\to\sigma_2)}};
    {\CoTyping \TEnv {\nth i \Co} {\tau_i \teq \sigma_i}}}}

\newcommand\CoForall{
  \ib{\irule[\trule{co-forall}]
    {\CoTyping {\TEnv,\alpha} \Co {\tau_1 \teq \tau_2}};
    {\CoTyping \TEnv {\Forall\alpha\Co} {(\Forall\alpha\tau_1) \teq (\Forall\alpha\tau_2)}}}}

\newcommand\CoInst{
  \ib{\irule[\trule{co-inst}]
    {\ValidType\TEnv\tau}
    {\CoTyping {\TEnv} \Co {\Forall\alpha\sigma_1 \teq \Forall\alpha\sigma_2}};
    {\CoTyping \TEnv {\Co@\tau} {\sigma_1[\alpha/\tau] \teq \sigma_2[\alpha/\tau]}}}}
   
\newcommand\CoRefl{
  \ib{\irule[\trule{co-refl}]
    {\ValidType\TEnv\tau};
    {\CoTyping \TEnv {\refl{\tau}}:\tau\teq\tau}}}

\newcommand\CoSym{
  \ib{\irule[\trule{co-sym}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \tau_2}};
    {\CoTyping \TEnv {\sym{\Co}} {\tau_2\teq\tau_1}}}}

\newcommand\CoTrans{
  \ib{\irule[\trule{co-trans}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \tau_2}}
    {\CoTyping \TEnv \MoreCo {\tau_2 \teq \tau_3}};
    {\CoTyping \TEnv {\comp \Co \MoreCo} \tau_1\teq\tau_3}}}

\newcommand\CoNth{
  \ib{\irule[\trule{co-nth}]
    {\CoTyping \TEnv \Co {\TypeCtrs\many\tau \teq \TypeCtrs\many\sigma}};
    {\CoTyping \TEnv {\nth i {\Co}} {\tau_i\teq\sigma_i}}}}

\newcommand\CoTypeCtr{
  \ib{\irule[\trule{co-type}]
    {\TypeCtrs\co n \in \GEnv}
    {\many{\CoTyping {\GEnv;\VEnv} {\Co_i} {\tau_i \teq \sigma_i}}^{i<n}};
    {\CoTyping {\GEnv;\VEnv} {\TypeCtrs\many\Co} {\TypeCtrs\many\tau \teq \TypeCtrs\many\sigma}}}}

\newcommand\CoFam{
  \ib{\irule[\trule{co-fam}]
    {\FamCtrs\co n \in \GEnv}
    {\many{\CoTyping {\GEnv;\VEnv} {\Co_i} {\tau_i \teq \sigma_i}}^{i<n}};
    {\CoTyping {\GEnv;\VEnv} {\FamCtrs\many\Co} {\FamCtrs\many\tau \teq \FamCtrs\many\sigma}}}}

\newcommand\CoAxiom{
  \ib{\irule[\trule{co-axiom}]
    {\substack {\AxiomTy = \many{\Forall{\many\alpha}{\FamCtrs(\FamPattern) \teq \sigma}}\\
               \Axiom\co\AxiomTy \in \GEnv}}
    {\substack {\many{\ValidType{\GEnv;\VEnv}{\tau_i}} \\
        \forall j < i.~ \nc {\AxiomTy} {i} {\many\tau} {j}}}
    {\ValidCtx{\GEnv;\VEnv}};
    {\CoTyping {\GEnv;\VEnv} {\branch i {\many\tau}} {\FamCtrs (\FamPattern\many{[\alpha_i/\tau_i]}) \teq \sigma\many{[\alpha_i/\tau_i]}}}}}

% \begin{figure}[ht]
%     \footnotesize
%   \[
%     \begin{array}{c c c}
%     \TCast   % & \TTyAbs & \TTyApp
%     \end{array}
%   \]
%   \[  
%     \begin{array}{c c c}
%       \CoRefl & \CoSym & \CoTrans
%     \end{array}
%   \]
%   \[
%     \begin{array}{c c}
%       \CoArr     & \CoNthArr\\      
%       \CoTypeCtr & \CoNth\\
%       \CoForall  & \CoInst\\
%       \CoFam     & \CoAxiom
%     \end{array}
%   \]
%   \caption[Typing Judgments for \CLTF{}]{Typing Judgments \CLTF{}}
%   \label{fig:tf-closed-typing}
% \end{figure}
The above exercise also illuminates an important property of \CLTF:
if we have a type reduction from $\tau_1$ to $\tau_2$ then we can build a type predicate $\tau_1\teq\tau_2$.
We abuse the notation for entailment, $\GEnv\entails\tau_1\teq\tau_2$, to mean we can obtain the
type equality predicate $\tau_1\teq\tau_2$ by using all necessary instantiations of the axioms in $\GEnv$.
\begin{lemma}[Completeness of Type reduction]
  if $\manytystepsto\GEnv{\tau_1}{\tau_2}$ then $\GEnv\entails\tau_1\teq\tau_2$ 
\end{lemma}

%\subsubsection{Consistency and Goodness of Context}\label{subsec:tf-closed-consistency}
Consistency means we can never derive unsound equalites between value types,
such as $\texttt{Int}\teq\texttt{Bool}$, in the system. Value types ($\GTy$), in \CLTF are
type constants, $\TypeCtrs$, and function types $\tau_1\to\tau_2$.
Consistency of the type system hinges on the requirement that we have a consistent context.
We say that a ground context $\GEnv$ is consistent, when for all predicates $\GTy_1 \teq \GTy_2$,
which we can build from $\GEnv$, or $\GEnv\entails\GTy_1\teq\GTy_2$, the two following properties holds:
\begin{enumerate}
\item if $\GTy_1$ is $\TypeCtrs$ then, $\GTy_2$ is also $\TypeCtrs$
\item if $\GTy_1$ is $\tau_1\to\tau_2$ then, $\GTy_2$ is also $\tau_1\to\tau_2$.
\end{enumerate}

\begin{lemma}[Type Consistency]
  If $\GEnv$ is consistent then, \CLTF is type consistent.
\end{lemma}
In general, consistency for arbitrary contexts is difficult to prove.
We will take a conservative approach and enforce syntactic restrictions on the ground context.
\begin{defn}[$\Good\GEnv$]\label{def:good-ctx}
  A ground context ($\GEnv$) is good, written $\Good\GEnv$ when
  the following conditions are met for all $\Axiom\co\AxiomTy\in\GEnv$ and
  where $\AxiomTy$ is of the form $\many{\Forall{\many{\alpha_i}}\FamCtrs_i(\FamPattern_i)\teq\sigma}$:
  \begin{enumerate}
  \item There exists an $\FamCtrs$ such that  $\forall i.~\FamCtrs_i = \FamCtrs$,
    and no type pattern, $\FamPattern_i$, mentions a type family constructor.
  \item The binding variables, $\many{\alpha_i}$, occur at least once in the type pattern $\FamPattern_i$,
    on the left hand side of the equation.
  \end{enumerate}
\end{defn}
Given our characterization of type reduction in the previous section, we now have to show
that if we have $\Good\GEnv$ then, $\GEnv$ is consistent. One way to prove this is
via confluence of the type reduction relation. Type reduction relation given by the rule \trule{ty-$\beta$}
works only on type families and does not reduce any value types; making 
confluence a sufficient condition to ensure consistency. Now to prove confluence for type reduction,
we first prove that the rewrite relation has local confluence---whenever we have ${\tau_1}\teq{\tau_2}$, then 
then we can always find a common reduct type $\tau_3$ such that $\manytystepsto \GEnv {\tau_1} {\tau_3}$ and
$\manytystepsto \GEnv {\tau_2} {\tau_3}$---and finally, we appeal to Newman's lemma\cite{newman_theories_1942}
given below that completes the proof of confluence of type reduction.
\begin{lemma}[Newman]
  If a rewrite system is terminating and locally confluent then it is confluent.
\end{lemma}
The design of \CLTF does leave the door open for non-terminating type family definitions and 
we have to make do with a weaker consistency lemma than what we originally hoped for.
\begin{lemma}[$\GEnv$ Consistency]
  If $\tystepsto \GEnv \bullet \bullet$ is terminating, and $\Good\GEnv$ then $\GEnv$ is consistent.
\end{lemma}

% \subsection{Type safety of \CLTF{}}\label{subsec:tf-closed-safety}
\newcommand\SApp{
  \ib{\irule[\trule{s-app}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\Tm_2} {\Tm'_1\App\Tm_2}}}
}
\newcommand\STApp{
  \ib{\irule[\trule{s-tapp}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\tau} {\Tm'_1\App\tau}}}
}

\newcommand\SCApp{
  \ib{\irule[\trule{s-capp}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\Co} {\Tm'_1\App\Co}}}
}

\newcommand\SCast{
  \ib{\irule[\trule{s-cast}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\cast{\Tm_1}\Co} {\cast{\Tm'_1}\Co}}}
}

\newcommand\SBeta{
  \ib{\irule[\trule{s-$\beta$}];
    {\stepsto {(\Lam x \Tm_1)\App\Tm_2} {\Tm_1[x/\Tm_2]}}
  }
}
\newcommand\STBeta{
  \ib{\irule[\trule{s-T$\beta$}];
    {\stepsto {(\TLam \alpha \Tm)\App\tau} {\Tm[\alpha/\tau]}}
  }
}

\newcommand\SPush{
  \ib{\irule[\trule{s-push}]
    {\Co_1 = \sym{\nth 0 \Co}}
    {\Co_2 = \nth 1 \Co};
    {\stepsto {(\cast {\Lam x \Tm} \Co) \App \Tm_1} {\cast {(\Lam x \Tm)\App(\cast{\Tm_1} {\Co_1})} {\Co_2}}}
  }
}
\newcommand\STPush{
  \ib{\irule[\trule{s-tpush}];
    {\stepsto {(\cast {\TLam \alpha \Tm} \Co) \App \tau} {\cast {(\TLam \alpha \Tm)\App\tau} {\Co@\tau}}}
  }
}
\newcommand\STrans{
  \ib{\irule[\trule{s-trans}];
    {\stepsto {\cast {(\cast \Tm \Co)} \MoreCo} {\cast \Tm {\comp\Co\MoreCo}}}
  }
  
}

\section{Constrained Type families}\label{sec:tf-constrained}
In the previous section for closed type families, we made an implicit assumption
that all type families are total, in the sense their domain is all the types.
This has philosophical and practical consequences.
Consider the example as shown in \pref{fig:partial-tyfam}.
\begin{figure}[ht]
    \footnotesize
  \begin{tabularx}\textwidth{X X}
\begin{code}^^J
type family PTyFam a where^^J
\ \  PTyFam Int = Bool^^J
^^J
type family Loop a where^^J
\ \  Loop a = [Loop a]^^J
^^J
type family TEq a b where^^J
\ \  TEq a a = Int -> Int^^J
\ \  TEq a b = Bool^^J
\end{code}&%
\begin{code}^^J
g x = x : x -- Error^^J
^^J
TEq [a] a \ $\steps$\ $???$^^J
\end{code}
  \end{tabularx}
  \caption{Partial Closed Type Family}
  \label{fig:partial-tyfam}
\end{figure}

We know that !PTyFam Bool! has no satisfying equations associated with it
that gives it a meaning and never will in the future
as it is closed. So, is !PTyFam Bool! a type? 
The implementation of \CLTF in GHC\cite{ghc_2020}, a compiler for Haskell,
it is treated as a type. This has practical consequences. Consider the type !TEq [a] a! as shown above.
Our intuition is to reduce !TEq [a] a! to !Bool! as we can never have a list type, ![a]!,
equal to its element type, !a!.
Given our type reduction strategy described in \pref{def:ctf-simpl},
the first equation does not match !TEq [a] a! and the second equation does.
However, we cannot assert that !TEq [a] a! is apart from !TEq a b!. 
The reason being that there might exist a type family !Loop a! that reduces to ![Loop a]!.
Thus, !TEq [Loop Bool] (Loop Bool)! can reduce to !TEq [Loop Bool] [Loop Bool]!, and eventually rewrite to !Int -> Int!.
Hence, GHC does not reduce !TEq [a] a! to !Bool!; it uses an apartness check based on unification for
infinite types\cite{jaffar_efficient_1984} rather than Robinson's unification.
But GHC also not support infinite types; a declaration such as,
!g x = x : x!, does not type check as !g! is of type !$\forall$ a. ([a] ~ a) => a -> a!;
but the infinite type !Loop a! is accepted by GHC. We are thus left in a confusing situation
where we accept some problematic types, like !Loop a!, but not all like ![a] ~ a => a -> a!.

The nub of the issue is that there is a mismatch in our intuitive semantics of type families and their behavior.
We think of them as partial functions on types where each new equation extends its definition.
Instead we should be thinking of them as introducing a family of distinct types and
each new equation equates types that were previously not equal.
One possible solution to this conundrum is to reject the definition of infinite type families
like !Loop a! but this burdens the programmers by enforcing them to provide an evidence
to guarantee termination. Instead, we leverage the infrastructure that Haskell already has---qualified
types---to solve this problem using constrained type families (\QLTF).


% \subsection{Closed Typeclasses}
% Typeclasses can be extended to have new instances. Closed typeclasses, on the contrary,
% are classes that cannot be extended once they are defined. They mirror closed type families
% in the same way as no more equations can be added once a closed type family is defined.
% Instances for a closed typeclass and their resolution
% will be performed at operator's use site in a top to bottom order on instance declarations.

% For example, the type families !TEq a b! and !Plus m n! can be expressed
% in the closed typeclass world using !TEqC a b! and !PlusC m n! respectively as shown in \pref{fig:closed-tc-examples}.
% \begin{figure}[ht]
%     \footnotesize
%   \begin{tabularx}\textwidth{X X}
% \begin{code}^^J
% class LoopC where^^J
% \ \ type Loop^^J
% \ \ instance LoopC => LoopC where^^J
% \ \ \ \  type Loop = [Loop]^^J
% \end{code}&%
% \begin{code}^^J
% class PTyFamC a where^^J
% \ \ type PTyFam a^^J
% \ \ instance PTyFamC Int where^^J
% \ \ \ \ type PTyFam Int = Bool^^J
% \end{code}\\    
% \begin{code}^^J
% class \{-TOTAL-\} TEqC a b where^^J
% \ \ type TEq a b^^J
% \ \ instance TEqC a a where^^J
% \ \ \ \  type TEq a a = TT^^J
% \ \ instance TEqC a b where^^J
% \ \ \ \ type TEq a b = FF^^J
% \end{code}&%
% \begin{code}^^J
% class \{-TOTAL-\} PlusC m n where^^J
% \ \ type Plus m n^^J
% \ \ instance PlusC Z m where^^J
% \ \ \ \  type Plus Z m = Z^^J
% \ \ instance PlusC m n => PlusC (S m) n where^^J
% \ \ \ \  type Plus (S m) n = S (Plus m n)^^J
% \end{code}
%   \end{tabularx}
%   \caption{Closed Typeclasses Examples}
%   \label{fig:closed-tc-examples}
% \end{figure}
% In the constrained type families world, every closed type family will be associated with
% a closed typeclass. Any type family without an associated typeclass will be disallowed.
% For example, see !class PTyFamC!. The type for !sillyFst! in this system is no longer
% !$\forall$ a. a -> a! but instead it is !$\forall$ a. PTyFamC Bool => a -> a!, and the type
% checker will flag it as an error wherever it is used; there is no way to satisfy
% the instance !PTyFamC Bool!. The type family !Loop! will also need to have
% an associated typeclass !LoopC!. To declare an instance of !LoopC!
% where !Loop ~ [Loop]! we need to specify !LoopC! to be a constraint on the instance.
% This makes the use of !Loop! no longer threatens the type soundness as !LoopC! is unsatisfiable.

% Most type families are partial, only some are total and we would want
% the users to take advantage of this fact by allowing programmers to explicitly state totality.
% In general, checking for or inferring totality for a given closed type family is a hard problem,
% thus we would also give the users a way to let the compiler accept it without checking it.
% It would enhance usability of the system to express total type families. 

\subsection{Type matching and Apartness Simplified}
The type reduction in closed type families had a complex criterion for apartness check, which included
flattening and then checking if they had a unifier.
In constrained type families we neither have to depend on infinitary type unification
nor flattening of types. 
% The constraint of allowing only terminating
% type families can also be lifted it no longer threaten type soundness. 
Apartness in this system is just checking for failure of unification using
Robinson's algorithm.

\begin{defn}[\QLTF Type Reduction Strategy]\label{def:qtf-simpl}
  An equation, say $p$, given in the type family declaration can be used to simplify the type
  $\FamCtrs(\many\tau)$, if the two following conditions hold:
  \begin{enumerate}
  \item The left hand side of the equation matches the the type $\FamCtrs(\many\tau)$.
  \item All equations preceding $p$ are compatible with $p$ or do not match $\FamCtrs(\many\tau)$.
  \end{enumerate}
\end{defn}

\subsection{Formalizing Type reduction and Type Consistency}\label{subsec:tf-constrained-formal}
\QLTF is similar to \CLTF except for a few new constructs that
we highlight in \pref{fig:tf-constrained-system}. The type can be qualified with a predicate ($\Preds\then\tau$)
and the predicates are nothing but type equalites, of the form $\tau\teq\tau$ as before.
Each type equality equation is of the form $\Forall {\many\alpha~\many\chi}{\FamCtrs(\many\tau)\teq\sigma}$
where both $\many\tau$ and $\sigma$ do not have occurrence of any family type constructors. 
The equations are quantified not only by the type variables $\many\alpha$
but also over evaluation assumptions $\many\chi$.
The evaluation assumptions are of the form ($\alpha|c\co\FamCtrs(\many\tau)\teq\alpha$) and read as
``$\alpha$ such that $c$ witnesses $\FamCtrs(\many\tau)$ reduces to $\alpha$''.
We use these evaluation assumptions to allow type families on the left hand side
of the type equations written in the source program. For example,
the user written type equation  !F (F' a) a b = G a b!, where !G! and !F'! are type family constructors,
will be compiled to an equation: as
$\forall\alpha\beta~(b|c:\texttt{G}~\alpha\beta \teq b)(d|c':\texttt{F}'~\alpha\teq d).~\texttt{F}d~\alpha~\beta
\teq b$.
% Evaluation assumptions are essential to support axioms that mention
% type families on the right hand side of the equations in source.
We use $\chi$ to remind us that it is more specific than $\pi$; for any $\chi$,
the left hand side of the type equality is always a type family and right and side is a fresh variable.
% The $\tassume\chi\Tm$ is the construct that is used while working with total type families.
% It provides a sort of an escape hatch as we are guaranteed to obtain a type family free type
% after reducing a total type family.
\begin{figure}[ht]
    \footnotesize
  \[
    \begin{array}{l l l}
      &\text{Type family Constructors} &\FamCtrs,\MoreFamCtrs\\
      &\text{Type Constants} &\texttt{\TypeCtrs}\\      
      % \\
      % &\text{Type Validity}               &\ValidType \TEnv \tau\\
      % &\text{Proposition Validity}        &\ValidProp \TEnv \Preds\\
      % &\text{Assumption Validity}      &\ValidAssmp \TEnv {\many\chi}\\
      % &\text{Ground Context Validity}     &\ValidGCtx{\GEnv}\\
      % &\text{Variable Context Validity}   &\ValidVCtx\GEnv\VEnv\\
      % &\text{Context Validity}            &\ValidCtx\TEnv\\
      % \\
      % &\text{Term Typing}              &\Typing \TEnv \Tm \tau\\
      % &\text{Coercion Typing}          &\CoTyping \TEnv \Co \Preds\\
      % &\text{Resolution Validity}      &\ResTyping \TEnv {\many q} {\many\chi}\\
      \\
      &\text{Type reduction}              &\tystepsto\GEnv\bullet\bullet\\
      &\text{One Hole Type Context}    &\TEvalCtxt{\bullet}
    \end{array}
    \begin{array}{l l l l l}
      &\text{Types}           &\tau,\sigma  &\bnfeq \alpha \bnfor \tau\to\tau %\bnfor \Forall\alpha\tau
                                              \bnfor \FamCtrs(\many\tau) \bnfor \TypeCtrs
                                              \bnfor \text{\shaded{$\Preds\then\tau$}}&\\
      &\text{Value Types}    &\GTy         &\bnfeq \tau\to\tau \bnfor \TypeCtrs\\
      %&\text{Type family Pattern}     &\texttt{\FamPattern} &\bnfeq \many{\alpha \bnfor \GTy}\\
      &\text{Type Equality Predicate}      &\pi       &\bnfeq \tau\teq\tau\\
      &\text{Predicates}                   &\Preds    &\bnfeq \many\pi\\
      &\text{Axiom Equations} &\AxiomEq     &\bnfeq \text{\shaded{$\Forall{\many\alpha~\many\chi}{\FamCtrs(\many\tau)
                                              \teq \sigma$}}}\\
      &\text{Axiom Types}     &\AxiomTy     &\bnfeq \many\AxiomEq\\
      % &\text{Coercions}  &\Co,\MoreCo &\bnfeq c \bnfor \Co\to\MoreCo \bnfor \Forall\alpha\Co \bnfor \Co@\tau
      %                                   \bnfor \FamCtrs(\many{\Co}) \bnfor \TypeCtrs(\many{\Co})\\
      % &                  &            & \bnfor \nth i \Co \bnfor \refl\tau \bnfor \sym{\Co} \bnfor \comp\Co\MoreCo
      %                                   \bnfor \text{\shaded{$\Co_1\teq\Co_2\then\MoreCo$}}
                                        % \bnfor \text{\shaded{$\qbranch{i}{\many\tau}{\many q}$}} & \\
      &\text{Eval Assumption}   &\chi &\bnfeq \text{\shaded{$(\alpha|c : \FamCtrs(\many\tau) \teq \alpha)$}} \\
      &\text{Eval Resolution}   &q    &\bnfeq \text{\shaded{$(\tau|\Co)$}}\\      
      \\
      % &\text{Terms}      & \Tm        &\bnfeq x \bnfor \Lam x \tau \Tm \bnfor \Tm\App\Tm \bnfor\cast M \Co 
      %                                   \bnfor \TLam \alpha \Tm \bnfor \Tm\App\tau \bnfor\DataCtrs\many{e} \\
      % &                  &            & \bnfor \text{\shaded{$\Lam c \Preds \Tm$}} \bnfor \text{\shaded{$\Tm\App \Co$}}
      %                                   \bnfor \text{\shaded{$\tassume\chi\Tm$}} \\
      % &\text{Values}     &\Val        &\bnfeq \Lam x \tau \Tm \bnfor \DataCtrs\many\Tm \bnfor \TLam \alpha \Tm \bnfor
      %                                   \text{\shaded{$\Lam c \Preds \Tm$}}\\
      % \\
      &\text{Ground Context} &\GEnv   &\bnfeq \empt \bnfor \GEnv,\Axiom\co\AxiomTy
                                        % \bnfor \text{\shaded{$\GEnv,\FamCtrs\co_\top n$}} \bnfor \GEnv,\FamCtrs\co n
                                        % \bnfor \GEnv,\TypeCtrs \co n\\
      % &\text{Variable Context}&\VEnv  &\bnfeq \empt \bnfor \VEnv,\alpha \bnfor \VEnv,x\co\tau
      %                                   \bnfor \text{\shaded{$\VEnv,c\co\Preds$}}\\
      % &\text{Typing Context}  &\TEnv  &\bnfeq \GEnv;\VEnv\\
    \end{array}
  \]
  \caption[\QLTF]{Excerpt of \QLTF}
  \label{fig:tf-constrained-system}
\end{figure}

The valid types in this system are only those that mention type family constructors in the predicate set $\Preds$.
For example, the type !$\forall$m n. Addition m n => m -> n -> Result m n! would instead be written
as !$\forall$m n. Result m n ~ p => m -> n -> p!. This is an assertion that !Result m n! evaluates to a
type family free type.

% The new validity judgments reflect the above discussion. The rule \trule{v-qty} ensures
% that type equality coercions can appear only in $\Preds$. We do not have the rule \trule{v-tfctr}
% in this system to ensure values types do not mention type family constructors.
% The rule \trule{v-qtfp} replaces the rule \trule{v-tfp}. This means that arguments to type family
% constructors can mention type families and we no longer have to use special type patterns as in \CLTF's \trule{v-tfp}.
% The rule \trule{v-qgax} replaces the \trule{v-gax} that checks axiom equations are valid. This checks that the context
% is consistent by making sure it is \Good, as discussed in \pref{subsubsec:tf-constrained-goodness-consistency}.
% We also have two new classes of validity judgments, \trule{v-assmn} and \trule{v-assmc} check
% that the evaluation assumptions that appear in the axioms are valid, while rules \trule{v-rese}
% and \trule{v-resc} ensure that the evaluation resolutions are valid.

\newcommand\ResNil{
  \ib{\irule[\trule{v-rese}]
    {\ValidCtx \TEnv};
    {\ResTyping \TEnv \empt \empt}
  }
}
\newcommand\ResCons{
  \ib{\irule[\trule{v-resc}]
    {\ValidType \TEnv \sigma}
    {\CoTyping \TEnv \Co {\FamCtrs(\many\tau)\teq\sigma}}
    {\ResTyping \TEnv {\many q} {\many\chi[\alpha/\sigma]}};
    {\ResTyping \TEnv {(\sigma|\Co), \many q} {(\alpha|c\co\FamCtrs(\many\tau)\teq\alpha), \many \chi}}
  }
}

\newcommand\ValidQGndContextAxiom{
  \ib{\irule[\trule{v-qgax}]
    {\substack {\ValidGCtx\GEnv\\
        \fresh \Axiom\GEnv}}
    {\substack {{\many{\ValidType {\GEnv;\many\alpha_i,\TV{\many\chi}} {\tau_{0i}}}}\\
        {\many{\ValidProp{\GEnv;\empt}{\Forall{\many\alpha}{\FamCtrs(\many\tau)\teq\sigma}}}}}}
    {\substack {{\many{\ValidType {\GEnv;\many\alpha_i} {\many\tau_i}}}\\
      {\ValidAssmp {\GEnv;\many\alpha_i} {\many\chi_i}}}}
    {\FamCtrs\co n \in \GEnv};
    {\ValidGCtx{\GEnv,\Axiom\co\many{\Forall{\many\alpha~\many\chi}{\FamCtrs(\many\tau_i)\teq\tau_{0i}}}^{i<k}}}
  }
}

\newcommand\ValidNilAssmp{
  \ib{\irule[\trule{v-assmn}];
    {\ValidAssmp \TEnv \empt}}
}

\newcommand\ValidConsAssmp{
  \ib{\irule[\trule{v-assmc}]
    {\FamCtrs\co n \in \GEnv}
    {\many{\ValidType {\GEnv;\VEnv} {\tau_i}}^{i<n}}
    {\ValidAssmp {\GEnv;\VEnv,\alpha} {\many\chi}};
    {\ValidAssmp {\GEnv;\VEnv} {(\alpha|c\co\FamCtrs(\many\tau)\teq\alpha),\many\chi}}}
}
\newcommand\ValidQType{
  \ib{\irule[\trule{v-qty}]
    {\ValidProp \TEnv \Preds}
    {\ValidType \TEnv \tau};
    {\ValidType \TEnv {\Preds\then\tau}}}
}
\newcommand\ValidQTyFam{
  \ib{\irule[\trule{v-qtfp}]
    {\FamCtrs\co n \in \GEnv}
    {\many{\ValidType {\GEnv;\TEnv} {\tau_i}}^{i<n}}
    {\ValidType {\GEnv;\VEnv} \sigma};
    {\ValidProp {\GEnv;\VEnv} {\FamCtrs(\many\tau)\teq\sigma}}}
}


\newcommand\ValidQCoVar{
  \ib{\irule[\trule{v-qcovar}]
    {\ValidVCtx\GEnv\VEnv}
    {\ValidProp {\GEnv;\TEnv} \Preds}
    {\fresh c \VEnv};    
    {\ValidVCtx\GEnv{\VEnv,c\co\Preds}}
  }  
}


% \begin{figure}[ht]
%     \footnotesize
%   \[
%     \begin{array}{c c c}
%       \ValidQType & \ValidQTyFam\\
%       \ResNil & \ResCons\\
%       \ValidNilAssmp & \ValidConsAssmp
%     \end{array}
%   \]
%   \[
%     \begin{array}{c c}
%         \ValidQGndContextAxiom &      \ValidQCoVar 
%     \end{array}
%   \]
%   \caption{Validity Judgments for \QLTF}
%   \label{fig:tc-constrained-validity}
% \end{figure}


\newcommand\QCoAbs{
  \ib{\irule[\trule{t-coabs}]
    {\Typing {\TEnv,c\co\Preds} \Tm \tau};
    {\Typing \TEnv {\Lam c \Preds \Tm} {{\Preds\then\tau}}}}}

\newcommand\QCoApp{
  \ib{\irule[\trule{t-coapp}]
    {\Typing \TEnv \Tm {\Preds \then \tau}}
    {\Typing \TEnv \Co {\Preds}};
    {\Typing \TEnv {\Tm\App\Co} \tau}}}

\newcommand\QAssume{
  \ib{\irule[\trule{t-assum}]
    {\many{\ValidType {\GEnv;\VEnv} {\tau_i}}}
    {\FamCtrs\co_\top n \in \GEnv}
    {\Typing {\GEnv;\VEnv,\alpha,c\co\FamCtrs\many\tau\teq\alpha} \Tm {\tau}};
    {\Typing {\GEnv,\VEnv} {\tassume{(\alpha|c\co\FamCtrs\many\tau\teq\alpha)}\Tm} \tau}}}


\newcommand\QCoAxiom{
  \ib{\irule[\trule{co-qaxiom}]
    {\substack {{\Axiom\co\AxiomTy \in \GEnv}\\
        {\AxiomTy = \many{\Forall{\many\alpha~\many\chi}{\FamCtrs(\many\tau) \teq \sigma}}}}}
    {\substack {\many{\ValidType{\GEnv;\VEnv}{\tau_i}} \\
        \forall j < i.~ \nc {\AxiomTy} {i} {\many\tau} {j}}}
    {\substack {\ValidCtx {\GEnv;\VEnv}\\
        \ResTyping {\GEnv;\VEnv} {\many{q}} {\many\chi[\alpha_i/\tau_i]} }};
    {\CoTyping {\GEnv;\VEnv} {\qbranch i {\many\tau} {\many q}} {\FamCtrs (\many\sigma\many{[\alpha_i/\tau_i]}) \teq \sigma_0\many{[\alpha_i/\tau_i]}}}}
}

\newcommand\QCoQual{
  \ib{\irule[\trule{co-qual}]
    {\many{\Typing \TEnv {\Co_i} {\tau_i\teq\sigma_i}}^{i<3}};
    {\CoTyping \TEnv {\Co_1\teq\Co_2 \then\Co_3} {(\tau_1\teq\tau_2\then\tau_2)\teq(\sigma_1\teq\sigma_2\then\sigma_3)}}}}

\newcommand\QCoVar{
  \ib{\irule[\trule{co-var}]
    {c\co\Preds \in \VEnv};
    {\Typing {\GEnv;\VEnv} {c} \Preds}}
}

% \begin{figure}[ht]
%     \footnotesize
%   \[
%     \begin{array}[ht]{c c}
%       \QCoVar & \QCoAxiom\\
%       \QCoAbs & \QCoQual \\
%     \end{array}
%   \]
%   \[
%     \begin{array}{c c c}
%       \QCoApp & \QAssume
%     \end{array}
%   \]
%   \caption[Selected Typing Judgments for \QLTF]{Selected Typing Judgments \QLTF{}}
%   \label{fig:tf-constrained-typing}
% \end{figure}

% The typing judgments new to this system are shown in \pref{fig:tf-constrained-typing}.
% The rule \trule{t-coabs} abstracts over coercion variable while \trule{t-coapp} applies a coercion
% argument to a term. We have a new version of axiom application rule \trule{co-qaxiom}.
% It is very similar to \trule{co-axiom}, except that we need
% to provide extra validity resolutions $\many q$ that instantiate the validity assumptions $\many\chi$.
% The validity resolutions are of the form $(\tau|\Co)$ where the type $\alpha$
% in validity assumptions $(\alpha|c\co\FamCtrs(\many\tau)\teq\sigma)$ is instantiated to $\tau$ and
% $\Co$ proves the equality and instantiates $c$. This is exactly what the rule \trule{v-resc} does.
% % We write $[\chi/q]$ for a substitution where the assumption $\chi$ is substituted by $q$.
% Finally, The rule \trule{t-assum} is the special rule that says we are allowed to assume arbitrary applications
% of a type family would give us a type free type. We can indeed do this by the definition of total type family.

\newcommand{\QTyTopRed}{
  \ib{\irule[\trule{qty-$\beta$}]
    {
      \begin{array}{c}
        {\Axiom\co\AxiomTy\in\GEnv}\\
        {\AxiomTy_i = \Forall{\many\alpha_i~\many\chi_i}\FamCtrs(\many{\sigma_i}) \teq \sigma_0}\\
        {\forall j < i. ~\nc \AxiomTy i {\many\tau} j}
      \end{array}
    }
    {
      \begin{array}{c}
        {\many\chi_i = \many{(\alpha'|c\co\MoreFamCtrs(\many\tau')\teq\alpha')}}\\
        {\tystepsto \GEnv {\many{\MoreFamCtrs(\Subst_1\many\tau')}} \many{\tau_0}}
      \end{array}
    }
    { 
      \begin{array}{c}
        {\Subst_1 = \mgu{\many\sigma_i}{\many\tau}}\\
        {\Subst_2 = [\many{\chi_i}\mapsto\many{\MoreFamCtrs(\Subst_1\many\tau')\teq\tau_0}]}\\
        {\tau_1 = \Subst_1\Subst_2\sigma_0}
      \end{array}
    };
    {\tystepsto \GEnv {\TEvalCtxt{\FamCtrs(\many\tau)}} {\TEvalCtxt{\tau_1}}} }
}  

\begin{figure}[ht]
    \small
  \[
  \begin{array}{c}
    \QTyTopRed
  \end{array}
  \]
  \caption{Type reduction}
  \label{fig:tc-constrained-tyred}
\end{figure}

The type reduction relation is formalized using the rule \trule{qty-$\beta$}.
It does the heavy lifting of producing the correct substitutions
for types ($\Subst_1$) as well as evaluation resolutions ($\Subst_2$). The correct
equation selection is done by $\noconflict$ criterion which is slightly different than before,
as we have a weaker apartness check.
The specialty of this relation is that we ensure applying type arguments to type families only when
they satisfy proper constraints with the use of evaluation resolutions,
thus guaranteeing every type reduction to eventually obtain a type family free type.
Type family free types, or value types, do not reduce; none of the equations in the
ground context have left hand sides as a value type.
We can thus prove termination for the type reduction relation.

\begin{lemma}[\QLTF Type Reduction Terminates] For all types $\tau$, $\manytystepsto\GEnv\tau\GTy$\end{lemma}

The definition of goodness can now be relaxed from the restriction that type families
cannot appear in the left hand side of the type family equations.
The compilation of equations into axioms will ensure that the type family occurrences
will be abstracted out as evaluation assumptions $\chi$.
\begin{defn}[$\Good~\GEnv$ relaxed]
  A ground context ($\GEnv$) is good, written $\Good\GEnv$, when
  the following conditions are met for all $\Axiom\co\AxiomTy\in\GEnv$ and
  $\AxiomTy$ is of the form $\many{\Forall{\many\alpha_i~\many\chi_i}\FamCtrs_i(\many\tau_i)\teq\sigma}$:
  \begin{enumerate}
  \item There exists an $\FamCtrs$ such that  $\forall i.~\FamCtrs_i = \FamCtrs$.
  \item The binding variables $\many{\alpha_i}$ occur at least once in the type arguments $\many{\tau_i}$,
    on the left hand side of the equation.
  \end{enumerate}
\end{defn}
With the new reduction relation defined above, and knowing that it is always terminates,
we can use Newman's lemma\cite{newman_theories_1942} to prove that type reduction is confluent using
local confluence just as we did in \CLTF. However, we get a stronger type consistency lemma as we do not have to assume termination.
\begin{lemma}[$\GEnv$ Consistency] If $\Good\GEnv$, then $\GEnv$ is consistent \end{lemma}
\begin{lemma}[\QLTF Type Consistency] If $\GEnv$ consistent, then \QLTF is type consistent. \end{lemma}
% \subsection{Type safety of \QLTF}\label{subsec:tf-constrained-safety} 
% \newcommand\TQPush{
%   \ib{\irule[\trule{t-qpush}]
%     {\substack {{v = \Lam c \Preds \Tm}\\
%         {\MoreCo_0 = \nth 0 \MoreCo}}}
%     {\substack {{\MoreCo_1 = \sym{\nth 1 \MoreCo}}\\
%         {\MoreCo_2 = \nth 2 \MoreCo}}};
%     {\stepsto {(\cast v \MoreCo)\App \Co} {\cast {v\App(\comp{\comp{\MoreCo_0}{\Co}}{\MoreCo_1})} \MoreCo_2}}
%   }
%   }

% \newcommand\TQResolve{
%   \ib{\irule[\trule{t-qres}]
%     {\chi = (\alpha|c\co\FamCtrs(\many\tau)\teq\alpha)}
%     {\FamCtrs(\many\tau) \Downarrow q};
%     {\stepsto {\tassume\chi\Tm} {e[\chi/q]}}}
% }

% \newcommand\TQBeta{
%   \ib{\irule[\trule{t-c$\beta$}];
%     {\stepsto {(\Lam c \Preds \Tm)\App\Co } {\Tm[c/\Co]}}}
% }
% Selected rules for term evaluation are shown in \pref{fig:tf-constrained-opsem}.
% The rule \trule{t-qres} evaluates a constraint function application similar to function application
% while the rule \trule{t-qpush} splits the inner coercion $\MoreCo$ so that it can be commuted with
% the coercion application $\Co$. The rule \trule{t-qres} is the rule that illuminates the evaluation
% for total type family constructors. The clause $\FamCtrs(\many\tau) \Downarrow q$ says that we
% find a witness for $\FamCtrs(\tau)$ reduction to a ground type to build an appropriate evaluation resolution
% and apply it to the enclosing term.
% \begin{figure}[ht]
%     \footnotesize
%   \[
%     \begin{array}{c c c}
%       \TQResolve & \TQBeta & \TQPush
%     \end{array}
%   \]
%   \caption{Small Step Operational Semantics \QLTF}
%   \label{fig:tf-constrained-opsem}
% \end{figure}
% We can thus state the preservation and progress for this system as follows:
% \begin{lemma}[Preservation \QLTF]
%   If $\Typing \empt \Tm \tau$ and $\stepsto \Tm {\Tm'}$ then $\Typing \empt {\Tm'} \tau$
% \end{lemma}
% \begin{lemma}[Progress \QLTF]
%   If $\Typing {\Sigma;\empt} \Tm \tau$
%   then either $\Tm$ is a value, or $\Tm$ is a coerced value of the form $\cast {\Tm'} \Co$ where $\Tm'\in\Val$
%   or there exists a $\Tm_1$ such that $\stepsto \Tm {\Tm_1}$.
% \end{lemma}


% \section{Related Work}\label{sec:related-work}
% Functional dependencies have also been formalized using constraint handling rules (CHR),
% a technique from logic programming\cite{sulzmann_understanding_2007}. There is no known
% implementation of functional dependencies using CHR.

% There are several variations of type families that have been explored and implemented in GHC.
% Open type families\cite{schrijvers_type_2008}, which predates closed type families,
% are extendable in a sense that the programmer can add more equations.
% To maintain both, extensibility and compatibility, open type families disallow overlapping equations.
% A system with both closed type families and open type families can co-exist without hiccups. This is
% indeed the current implimentaion of GHC. The semantics of the instance equations is similar to
% that of unordered collection of type equations, unlike
% closed type families, where the equations are considered in a top to bottom fashion.
% Associated types\cite{chakravarty_associated_2005} are a syntactic variation of open type families.
% Each typeclass has an associated type parameterized over typeclass parameters. Each instance of such typeclass
% specifies what the associated type's interpretation in the context. Injective type families\cite{stolarek_injective_2015}
% uses the idea from functional dependencies to specify additional injective constraints that the type family instance
% should satisfy to aid type inference.

\section{Conclusion and Future Work}\label{sec:conclusion}
% All three systems described in the paper have a common property that they are based on
% the principle of type erasure. The type analysis is performed at compile time and
% the types are erased from the programs at runtime.
% This ensures that there is no runtime overheads because of types.
% Due to type safety properties of each of these systems, we are guaranteed
% that if a program passes the type check then it does not crash at runtime.
% A feature that we have not included in each of the systems is the system of kinds, or type of types.
% They provide a way to have partially applied data constructors. The reason to not include them is that
% they are orthogonal to our discussion. Adding them to the system will not change type safety of the language.

% With squinting eyes, typeclasses with functional dependencies and type families are trying to achieving the
% same goal---computation on types. While functional dependencies have a flavor of relations,
% type families have a flavor of equations. Haskell programmers using GHC,
% prefer functional programming over logic programming making type families their preferred choice.
% Further, a buggy implementation of functional dependencies in GHC, does not help its case either.
% A formal proof about the equality of the expressive power of functional dependencies and
% type families is an open problem\cite{TODO}. 

Type computation, either by functional dependencies or by type families
is an attractive feature for programmers as it considerably improves language expressivity.
From the above examples, we might think that functional dependencies are morally equivalent to type families.
In such a case we would expect to have one of the two cases to be true
1) translation mechanism that can go from one style to another or 2)
translation of both the language features into a common intermediate language.
As of now, both of these remain an active area or research\cite{karachalias_elaboration_2017,sulzmann_understanding_2007}.

The type consistency formalization of closed type families hinges on the assumption that
type family reduction are terminating. This problem is effectively solved by using constrained type families.
In conclusion, the motivation of constrained type families is to reunite
the idea of functional dependencies and type families that had previously diverged.
The use of equality constraints to ensure that type family applications are well defined
is reminiscent of the use of functional dependencies to ensure typeclass instances are well defined.
\newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{typeclasses}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
