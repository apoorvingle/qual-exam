%% FIXME:
%% 1. Space hacking for definitions and list items
%% 2. Tables and array looks

\newif\ifcomments\commentstrue

\RequirePackage[svgnames,dvipsnames,prologue]{xcolor}

\documentclass[format=sigplan,manuscript,review,screen,nonacm,margin=1in]{acmart}

\usepackage{typeclasses}

\title{Dialects of Type Computations in Haskell}
% \subtitle{Typeclasses, functional and Type Families}
\author{Apoorv Ingle}
\orcid{0000-0002-7399-9762}
\affiliation{%
  \institution{University of Iowa}
  \department{Department of Computer Science}
  \streetaddress{McLean Hall}
  \city{Iowa City}
  \state{Iowa}
  \country{USA}}
% \keywords{typeclass, type family}

\begin{document}
\begin{abstract}
In modern programming languages, it is a well perceived notion
that static types have a two fold advantage (1) it serves as a guiding tool to help programmers
write correct code and (2) the type checker can help identify
code that does not have a correct behavior. An expressive type system
can guarantee stronger claims about written programs. Enabling programmers to perform
type level computations is a way to make the type system expressive.
During the past three decades, for languages that supports typeclasses, there have been proponents
of two different styles of type level computations---functional dependencies and type families.
In this paper we describe these two language features with examples, formalize them and
conclude with comparing and contrasting them.
\end{abstract}
\maketitle
%\pagestyle{plain}

\section{Introduction}
Parametric polymorphism is a powerful technique to write programs that can work on
a wide variety of types. The identity function, !id!, that takes an input and returns it
without modification has the type !id :: $\forall$a. a -> a!.
We also need to have some way of taming unconstrained polymorphism.
For example, an addition operation, !add!, on all types does not necessarily make sense,
i.e. the type !add :: $\forall$ a. a -> a -> a! is too general for describing addition.
Programming languages that support functions as first class citizens
cannot get away with having unconstrained parametric polymorphism.
Typeclasses\cite{wadler_polymorphism_1989} give a mechanism
of having constrained polymorphic types. Theory of qualified types\cite{jones_qualified_1994}
justifies the use of typeclasses to achieve constraint polymorphism without compromising
type safety by having predicates as a part of type syntax.

An alternative view of typeclasses is to define relations on types. As the
type checker is guaranteed to terminate, it gives programmers a way to encode computations at type level.
A typeclass with $n$ parameters builds an $n$-tuple relation on types. However, using
relations to encode computations is cumbersome due to its verbosity. A new language feature
called type families\cite{schrijvers_towards_2007} was introduced in Haskell
to be able to express type computations in a more obvious style using pattern matching at typelevel.
Naturally, enabling type families warrants a richer system of types.
The types in this system include a special type called coercion. A coercion is an evidence
that states equality between types. Ensuring type safety for such a language is nontrivial.

The scope of the current article is as follows.
We give examples with intuitive set semantics for typeclasses in the beginning of \pref{sec:tc},
and then describe functional dependencies\cite{jones_tcfd_2000} with some examples in \pref{subsec:fd}.
We formalize them in \pref{subsec:tc-formal} and describe the consequence of introducing
functional dependencies by improving type inference and detecting ambiguous types in \pref{subsec:fd-improve}.
We also give a brief description of type safety for this system in \pref{subsec:tcfd-safety}.
We then describe two flavors of type families---closed type families\cite{eisenberg_typefamilies_2014}
in \pref{subsec:tf-closed} and their generalization constraint type families\cite{morris_typefamilies_2017}
in \pref{subsec:tf-constrained} with examples and their respective formalization in \pref{subsec:tf-closed-formal}
and \pref{subsec:tf-constrained-formal}. We then give some details about the type safety of
each system in \pref{subsec:tf-closed-safety} and \pref{subsec:tf-constrained-safety} respectively.
To conclude we give some related work in \pref{sec:related-work}, and draw some comparisons
between the three systems while point towards some open research questions in \pref{sec:conclusion}.

\section{Typeclasses}\label{sec:tc}
Typeclasses can be thought of as collection of types. Each typeclass is accompanied by its member
functions or operators that a particular instance of the typeclass supports. For example,
equality on types can be expressed as a typeclass !Eq a! in concrete Haskell syntax as follows:\newline
\begin{tabular}{l l l l}
\begin{code}
class Eq a where
  (==) :: a -> a -> Bool
\end{code}&%
\begin{code}
instance Eq Int where
  a == b = eqInt
\end{code}&%
\begin{code}
instance Eq Char where
  a == b = eqChar
\end{code}&%
\begin{code}
instance Eq Bool where
 a == b = $\ldots$
\end{code}
\end{tabular}

The instances of !Eq! typeclass can be types such as integers (!Int!), characters (!Char!) and Booleans (!Bools!).
It may not be meaningful to define equality on function types (!a->b!). Thus, the operator
!(==)! is not truly polymorphic in this sense as it cannot operate on function types rather
it is constraint to only those types that have an instance defined. We make this explicit by writing
the type of the operator !(==) :: $\forall$a. Eq a => a -> a -> Bool!. 
% \AI{We don't need the history portion here. Appeal the set intuition of type classes}
%% The problem
% Typeclasses were originally introduced to avoid the problem of implicit code blowup while supporting
% overloading of operators in languages based on polymorphic lambda calculus.
% For example, consider built-in or primitive types such as \texttt{Int} and \texttt{Char}.
% We want to define a function !inc :: a -> a! that when applied to a value of type
% \texttt{Int} returns the next \texttt{Int}, similarly, when applied to a value of type \texttt{Char}
% returns the next \texttt{Char}. Both these types would have specialized versions of how
% to return the next value say !incInt :: Int -> Int! and !incChar :: Char -> Char!.
% Now, all the functions that use the polymorphic function !inc! would need to resolve
% the overloaded operator !inc! it to a specific instance during compile time. In a na\"ive compilation strategy,
% such a function would need to be generated for each instance of the ground type where it is defined.
% In this example, we would have to generate two copies, one for \texttt{Int} and other for \texttt{Char}.
% While this method works, this is inefficient and leads to a code blowup during compile time.

%% The solution
% To solve this problem of code blowup, \cite{wadler_polymorphism_1989} suggested the use of dictionaries.
% In this method, each polymorphic function would be rewritten by the compiler where it
% would take in an extra implicit dictionary argument that is parameterized by the type to be used at call site.
% Continuing with the !inc! example its new type would be !inc :: Incable a => a -> a!.
% To assert that any type \texttt{$\tau$} indeed is defined on the function !inc! we declare
% a typeclass instance !Incable $\tau$! with !inc! function associated with it.
% This can be achieved in Haskell using the syntax shown in \pref{fig:typeclass-example}.

% \begin{figure}[ht]
%   \begin{tabular}{c c c}
%     \begin{code}
%       class Incable a where
%         inc :: a -> a
%     \end{code}&%
%                 \begin{code}
%                   instance Incable Int where
%                     inc = incInt
%                   \end{code}\\
%     \begin{code}
%       inc :: Incable a => a -> a
%       inc d c = d.inc c
%     \end{code}&%
%                 \begin{code}
%                   instance Incable Char where
%                   inc = incChar
%                 \end{code}
%   \end{tabular}
%   \caption{\texttt{Incable} Typeclass and its Instances}
%   \label{fig:typeclass-example}
% \end{figure}
\AI{Can also use Ord to reduce the space?}
One can even have a hierarchy of typeclasses. From abstract algebra, A !Semigroup! is a collection of
elements closed under an associative binary operation and a !Group! a !Semigroup!
that also has inverses and an identity element. To model integers
as a group with addition as a binary operation and $0$ as the identity element with the inverse operation
being just the negative of the integer we can define the instances !Semigroup Int! and !Group Int!
as shown in \pref{fig:type-class-hierarchy}. In this example, we say !Semigroup! is a superclass of !Group!.
We would need to have a check that ensures superclass constraints are satisfied to allow typeclass instance.
% The dictionary of !Group! would also contain the method
% of its superclass !Semigroup! as well as the methods declared within the class.
\begin{figure}[ht]
  \begin{tabular}{l l}
    \begin{code}
      class Semigroup a where
          (*) :: a -> a -> a

      instance Semigroup Int where
          a * b = a + b

      instance (Semigroup a, Semigroup)
          => Semigroup (a, b) where
          (a1, b1) * (a2, b2) = (a1 * a2, b1 * b2)
    \end{code}&%
    \begin{code}
      class Semigroup a => Group a where
          ident  :: a
          invert :: a -> a
      
      instance Group Int where
          ident   = 0
          invert a = -a 

      instance (Semigroup a, Semigroup b)
          => Group (a, b) where
          ident  = (ident, ident)
          invert (a, b) = (invert a, invert b)
    \end{code}
  \end{tabular}
  \caption{A Hierarchy of Typeclasses}
  \label{fig:type-class-hierarchy}
\end{figure}
In set semantics, we can think of typeclasses to be a set of all the types that are its valid instances.
Thus, $\texttt{Eq} = \Set{\texttt{Int}, \texttt{Char},\texttt{Bool}}$,
$\texttt{Group} = \Set{\texttt{Int}} \cup \Set{(\tau_1, \tau_2) \mid \tau_1, \tau_2 \in \texttt{Group}}$ and
$\texttt{Semigroup} = \Set{\texttt{Int}} \cup \Set{(\tau_1, \tau_2) \mid \tau_1, \tau_2 \in \texttt{Semigroup}}$.

%% Comparison with other languges
% In comparison with other languages, as a first approximation, typeclasses look like interfaces from
% object oriented languages like Java. However, there are subtle differences. It would not be possible
% to define an interface like !Semigroup! in Java that is polymorphic in more than one parameter.
% This would have to be achieved using generics such as !interface Comparable<T>(T obj) { ... }!.
% Typeclasses are also different from ML modules as the latter helps achieve data abstraction while the former does not.

%% What are these?
There is nothing special about the typeclass to have only one type parameter.
It would be natural to have multiple type parameters. A multiparameter typeclass
with $n$ type parameters would then represent a relation over $n$ types.
An example of such a typeclass would be !Add a b c! that represents
all the types that support an add !(+)! operation. We would expect to have instances such as !Add Int Int Int!, 
!Add Int Float Float!, and so on. The instances of typeclass !TEq! would assert that types !a! and !b! that are equal.

\begin{figure}[ht]
  \begin{tabular}{l l l}
    \begin{code}
class Add m n p where
  (+) :: m -> n -> p
    \end{code}&%
    \begin{code}
instance Add Int Float Float where
  (+) a b = addFloat (toFloat a) b
    \end{code}&%
    \begin{code}
instance Add Int Int Int
  (+) a b = intAdd a b
    \end{code}\\
    \begin{code}
class TEq a b
    \end{code}&%
    \begin{code}
instance TEq Int Int
    \end{code}&%
    \begin{code}
instance TEq Char Char
    \end{code}
  \end{tabular}
  \caption{multiparameter Typeclasses}
  \label{fig:multip-typeclass}
\end{figure}
%% What do they accomplish?
In \pref{fig:multip-typeclass}, notice how !TEq! typeclass has no operations associated with it.
In this view, we are no longer using typeclasses to give an implementation of polymorphic
functions at specific types. Its sole purpose is to define a predicate (or a relation) on types. 
We can describe !Add! and !TEq! in simple set semantics as, $\texttt{Add} = \Set{(Int, Int, Int), (Int, Float, Float)}$
and $\texttt{TEq} = \Set{(Int, Int),(Char, Char)}$.

%% What problems do they introduce?
Multiparameter typeclasses, while being powerful are problematic in practice.
It is possible for a programmer to declare conflicting instances of such a typeclass.
Declaring !Add Int Float Float! and !Add Int Float Int!
would be conflicting as the type inference algorithm will no longer be able to resolve
the overloaded operator !+!. The type system has no mechanism
to identify such inconsistent instances and disallow them at compile time. The situation gets worse
as the type error would be raised at the use of the overloaded operator confusing the programmer about the
cause of the issue. However, there may be cases where we do would want to allow such definitions as well.
Consider a class !Convert a b! that converts a type !a! to a type !b!. All four instances of this class---
!Convert Int Char!, !Convert Char Int! !Convert Int Int! and !Convert Char Char!---are valid and consistent.

\subsection{Functional Dependencies with Examples}\label{subsec:fd}
%% How does this solve the previous problem
Typeclasses with functional dependencies\cite{jones_tcfd_2000} is a generalization of multiparameter typeclasses.
It introduces a new syntax where the user can specify a relation between the type parameters
while declaring the typeclass. There is no change while declaring the instances for the typeclasses.
In this new syntax !x -> y!, means that ``\texttt{x} uniquely determines \texttt{y}''.
As shown in \pref{fig:add-tc-fd}, !Convert a b! typeclass is just a binary relation on types while 
the new !Add m n p! typeclass relates the type parameters such that !m! and !n! determine !p!.
We can also have multiple functional dependencies as with !TEq! typeclass where !t! and !u! determine
each other. In general we can have multiple parameters on both sides of the arrow,
!$x_1$, ..., $x_m$ -> $y_1$, ..., $y_m$!.
\begin{figure}[h t]
  \begin{tabular}{l l}
    \begin{code}
      class Convert a b where
         to :: a -> b

      class TEq t u | t -> u, u -> t
      instance TEq t t
      
      class Add m n p | m n -> p where
        (+) :: m -> n -> p
      instance Add Int Int Int where
         ... 
    \end{code}&%
    \begin{code}
      instance Add Int Float Float where
         ...
      instance Add Float Int Float where
         ...
      instance Add Int Float Int -- Error!

      e :: (Add Int Float b, Add b Int c) => c
      e = (1 + 2.0) + 3
    \end{code}
  \end{tabular}
  \caption{\texttt{Add} with Functional Dependency}
  \label{fig:add-tc-fd}
\end{figure}
The programmer can use functional dependencies to specify the intention of the typeclasses
more accurately. Further, the compiler now has a way to detect inconsistencies with
the declared instances and flag an error whenever it detects one.
This improves error reporting as it flags errors at inconsistent declaration site
rather previously confusing at the operator use site. For example,
the functional dependency on !m n -> p! can now help the compiler flag
the instance !Add Int Float Int! as a conflicting instance
!Add Int Float Float! because !Int! and !Float! together should uniquely determine a type.

Consider the expression !e = (1 + 2.0) + 3!. Due to the use of the overloaded operator !(+)! in !e!,
the principal or the most general type of !e! inferred by the type inference algorithm would be
!(Add Int Float b, Add b Int c) => c!. But notice how !b! does not occur on the right and
side of the !=>!. This makes the type ambiguous. There is no way for the compiler
to instantiate the type variable !b! to a specific value and
be able to choose a particular instance of the operator. In general, ambiguous types do not have
a well defined semantics in Haskell overloading. However, due to the use of functional dependency,
this seemingly ambiguous type can be converted to an unambiguous type.
We can infer that !b! has to be !Float! as it is determined by the other two type parameters of the class instance.
Thus, !e :: (Add Int Float Float, Add Float Int c) => c!.
We can even go a step further and improve this seemingly polymorphic type and the functional dependency
to deduce that type type variable !c! has to be !Float!.
Without the functional dependency on the class, it would not be impossible
to make such an inference.

\begin{figure}[ht]
  \begin{tabular}{l l}
\begin{code}
data Z   -- Type level Zero
data S n -- Type level Successor
\end{code}&%
\begin{code}
class IsPeano c
instance IsPeano Z
instance IsPeano n => IsPeano (S n)
\end{code}\\
\begin{code}
class (IsPeano m, IsPeano m, IsPeano p)
  => Plus m n p | m n -> p
instance IsPeano m => Plus Z m m
instance Plus n m p => Plus (S n) m (S p)
\end{code}&%
\begin{code}
data Vector s e = Vec (List e)
concat_vec :: Plus m n p
     => Vector m e -> Vector n e -> Vector p e
concat_vec (Vec l1) (Vec l2) = Vec (append l1 l2)
\end{code}
  \end{tabular}
  \caption{Peano Arithmetic and Vector Operations with Functional Dependencies}
  \label{fig:peano-arith}
\end{figure}
With functional dependencies at our disposal, We can even perform peano arithmetic at type level
as shown in \pref{fig:peano-arith}. First we define two datatypes !Z! and !S n!
that represent the number zero and successor of a number !n!, respectively.
The instances of !IsPeano! assert that !Z! is a peano number also, if !n! is a peano number
then !S n! is a Peano number. The instances of !Plus! typeclass relates three peano numbers where the relation
holds if the first two peano numbers add up to be equal to the third. Thus, !Peano Z m m! asserts
that !0 + n = n! while !Plus n m p => Plus (S n) m (S p)! asserts that if n + m = p then (1 + n) + m = (1 + p).
The !TEq! instance holds when there is an appropriate !Plus! instance defined. Notice how the functional dependency
!t -> u, u -> t! describes the fact that all instance of !TEq! should have the same type for !t! and !u!. Without this
functional dependency it would impossible to enforce the criteria for a type class whose instances were intended for
equal types. The !concat_vec! function demonstrates why type level computation would be useful
for a linear algebra library. The type of !concat_vec! says that the size of the resulting
vector is the sum of the sizes of the argument vectors.

\subsection{Formalizing Type classes with Functional Dependencies}\label{subsec:tc-formal}
%% Fix the language
To formalize the system, we first need to fix the language.
The surface syntax, the one that the user writes, in shown in \pref{fig:ty-fd-formal}.
We will call this \TCFD{}.
% syntax for types
The syntax of types ($\tau$) consists of  type variables ($\alpha$),
functions ($\tau\to\sigma$), and type constructors $\TypeCtrs\many{\alpha}$.
The qualified types ($\rho$) are given as $\ClassCtrs\many\alpha\then\tau$
where $\ClassCtrs\many\alpha$ constrains the type $\tau$. Type schemes ($\sigma$) are quantified constraint types.
%% The term language
The terms or expressions in the language ($e$) consists of countably
infinite set of variables ($x, y$), functions ($\Lam x \tau e$),
function applications ($e_1\App e_2$), overloading of operators is achieved by ($\Let x {e_1} {e_2}$), and
data constructors ($\DataCtrs$) define values for a user defined type.
% Typeclasses and datatypes
We have syntax that enables the programmer to declare their own types using the keyword !datatype!
followed by a list of data constructors, declare typeclasses with a keyword !class! with a list
of functional dependencies, and a list of typeclass methods and their type signature
following the keyword !where!. Instances of typeclasses are declared using
the keyword !instance! and definitions of each of the class method following the !where! keyword.
Both the typeclass declarations and instance declarations can optionally have a list of
additional prerequisite constraints on the right hand side of !=>!.
% Although we are using the same symbol !(->)! to denote functional dependency and function types,
% the context of its appearance will differentiate its meaning. Same is the case for !=>! where it is used
A typical program in this language is a collection of datatype declarations,
class declarations with their instances and terms. Values in this system are data constructors and lambda expressions.

\begin{figure}[ht]
  \[
  \begin{array}{l l l}
    &\text{Term Variables}     &x, y\\
    &\text{Type Variables}     &\alpha, \beta\\
    &\text{Class Constructors} &\ClassCtrs\\
    &\text{Data Constructors}  &\DataCtrs\\
    &\text{Type Constructors}  &\TypeCtrs\\
    \\
    &\text{Term Typing}        &\QTyping \Preds \TEnv \Tm \tau

  \end{array}
  \begin{array}{l l l l}
    &\text{Predicates}      &\Preds &\bnfeq \many{C\many{\alpha}}\\
    &\text{Types}           &\tau   &\bnfeq \alpha \bnfor \tau\to\tau \bnfor \TypeCtrs\many{\alpha}\\
    &\text{Qualified Types} &\rho   &\bnfeq \tau \bnfor \Preds\then\tau\\
    &\text{Type Schemes}    &\sigma &\bnfeq \forall{\many\alpha}.\rho\\
    &\text{Terms}           &\Tm    &\bnfeq x \bnfor \Tm\App \Tm \bnfor \Lam x\tau \Tm \bnfor \Let x {\Tm} {\Tm}\\
    &                       &       &\bnfor \DataCtrs\many{\Tm} \bnfor \texttt{\textbf{case }} e \texttt{\textbf{ of }} \many\Ptrns\\
    &\text{Values}          &\Val   &\bnfeq \Lam x \tau \Tm \bnfor \DataCtrs\many\Tm\\
    &\text{Patterns}        &\Ptrns &\bnfeq D\many\Tm \to \Tm\\
    &\text{Typing Environment} &\TEnv &\bnfeq \empt \bnfor \TEnv,x\co\sigma
    \\
    &\text{Data Declarations}     &    &T \many{\alpha} = \many{\DataCtrs \many{\alpha}}\\
    &\text{Class Declarations}    &    &\texttt{\textbf{class}}\ \Preds \then \ClassCtrs\many{\alpha}
                                         \mid \many{\many{\alpha} \to \many{\alpha}}
                                             \texttt{\textbf{ where }}\many{x :: \sigma}\\
    &\text{Instance Declarations} &    &\texttt{\textbf{instance}}\ \Preds \then \ClassCtrs\many{\tau}~
                                         \texttt{\textbf{ where }}~ \many{x = e}
  \end{array}
  \]
  \caption{\TCFD}
  \label{fig:ty-fd-formal}
\end{figure}

\subsubsection {Notations and Definitions}\label{subsubsec:fd-notations}
To avoid syntax clutter for formalization we will use some notations described as follows.
We would use the subscripts on objects ($\alpha_1,\ldots, \alpha_n$) to mean they are distinct.
$\many{\alpha}$ means a collection of $\alpha_1, \alpha_2, ..., \alpha_n$ items of arbitrary length.
We use $S_1 \setdiff S_2$ to denote the set difference operation. For an object $X$,
$\TV{X}$ is the set of variables that are free in $X$.
We write $M[\many{x}/\many{y}]$ to denote the substitution where each variable
$x_i$ is mapped to $y_i$ in $M$. Alternatively we also
write $\Subst X$ for an substitution $\Subst$ applied to object $X$.
We denote the most general unifier for two types $\tau_1$ and $\tau_2$ (if it exists),
by $\mgu {\tau_1} {\tau_2}$\cite{robinson_machine-oriented_1965}. For the sake of convinience,
we would also write $\mgu{\many{\tau_1}}{\many{\tau_2}}$ to give us a composition of most general
unifier for each pairs of types $(\tau_{1i}, \tau_{2i})$.
% We abbreviate the $\ClassCtrs\many\alpha$ as $\Preds$ and $\MorePreds$
For a typeclass declaration we write !class P => C $\many t$!, where !$\many t$! are the type parameters
of the class and \Preds{} are the constraints that must be satisfied.
We denote the set of functional dependencies of class !C! with $\fundep{C}$.
We write !$\many X$ -> $\many Y$! for an arbitrary functional dependency.
The determinant of a functional dependency is denoted by $t_{\many X}$
and the dependent is denoted by  $t_{\many Y}$. $\TV{C}$ will be the set of type parameters
of the class !C!. A predicate set $\Preds$ is satisfiable if there exists a substitution,
$\Subst$, such that $\emptyset\entails \Subst\Preds$.
We write $\satisfyable\Preds = \Set{\Subst \mid \emptyset \entails \Subst P}$
to mean the set of all substitutions that satisfy $\Preds$.

For example, for a typeclass declaration !class Add m n p | m n -> p!,
we have, $t = (a, b, c)$, $\fundep{Add}=$!$\{$ m n -> p $\}$!, $\TV{C} = \Set{m, n, p}$.
For the functional dependency !m n -> p!, we have, $t_X = {(\texttt{m},\texttt{n})}$ and $t_Y = {(\texttt{p})}$.
Given a set of functional dependencies $\texttt{J}$, we define the closure operation,
\todo{fix this definition. It seems broken}
$\closure Z {\texttt{J}}$, on $Z \subseteq t$, to be equal to all the type parameters
that are determined by set of the functional dependencies \texttt{J}.
Thus, $\closure {\Set{p}} {\fundep{Add}} = \Set{p}$,
$\closure {\Set{m}} {\fundep{Add}} = \Set{m}$ while $\closure {\Set{m, n}} {\fundep{Add}} = \Set{m, n, p}$.

%% Introduction to type system
% \cite{jones_qualified_1994} uses a general framework called a theory
% of qualified types to formalize the type system for \TCFD{}.
% In this framework, the predicates on types are part of the syntax of the type language.
% The predicates on types in our language are nothing but typeclasses.
% Declaring instances is the assertion that the types satisfy the predicate.
\subsubsection{Type system for \TCFD{}}
We say that the tuple $\QTyping \Preds \TEnv \Tm \tau$ to be a judgment
that holds when there is a typing derivation that shows $\Tm$ has type $\tau$
with predicates $\Preds$ being satisfied and the free variables in $\Tm$
are given types by the typing environment $\TEnv$, that maps term variables to its types.
% \AI{Should this be a declarative type system or a syntax directed type inference algorithm?}
% This should be a declarative type system. Algorithmic stuff can be asserted to be true.
The typing judgments for the language are shown in \pref{fig:tcfd-typing}.
The generalize function $\Gen \TEnv \tau$ quantifies
all the free variables of the type $\tau$ that do not occur in the domain
of the type environment $\TEnv$, i.e., $\Gen \TEnv \tau = \forall(\TV\tau\setdiff\dom\TEnv).\tau$.
The instantiate function $\Ins\sigma$ maps each quantified variable in $\sigma$ to a
fresh variable, i.e. if $\sigma=\forall\many{\alpha}.\Preds\then\tau$,
then $\Ins\sigma = \Preds[\many{\alpha}/\many{\beta}]\then\tau[\many{\alpha}/\many{\beta}]$
where $\many\beta$ are fresh. The variables need to be fresh to avoid
any conflict with the existing type variables. The typing rule
for function abstraction $\trule{\I\to}$ says that if we can show a typing derivation
where the body of the function $\Tm$ has the type $\tau$ with the typing environment
extended with the variable that represents the argument for the function with type $\tau_1$,
then we have a judgment that shows the lambda term
has type $\tau_1\to\tau_2$. The typing judgment for function application rule $\trule{\E\to}$
says that if we can show that the left hand term $\Tm_1$ has type $\tau_2 \to\tau$ and additionally we can
show that the right hand term $\Tm_2$ has type $\tau_2$ then we can show
that the term $\Tm_1\App\Tm_2$ has type $\tau$. The rule $\trule{tlet}$ says that we can show
that the type of $\Tm_2$ with a variable $x$ bound to a term $\Tm_1$ is of type $\tau_2$
only if we can build a derivation that shows $\Tm_1$ as $\tau_1$ and we can show that
$\Tm_2$ has type $\tau_2$ with typing environment extended with the variable $x$ mapped
to the generic instance of $\tau_1$. The $\trule {tlet}$ is in essence overloading in action
as the variable $x$ is assigned a generic type. The rule $\trule{tvar}$ says that to show
that the type of the variable $x$ is $\tau$ we need to look it up in our typing environment
and instantiate it with fresh variables. The rule $\trule{tdata}$ says that if need to show
that the datatype constructor $\DataCtrs\many{\Tm_i}$ has a user defined type $T\many\tau$
then we need to show that each of the arguments are well typed
and the data constructor has the right type as given by its declaration.
The data constructor case can be viewed as a generalized version of function types as $\tau_1\to\tau_2$ is
a type constructor and $\Lam x \tau \Tm$ as its data constructor.
% The goal of the type inference algorithm
% is to find the most general pair, $(\Preds, \tau)$ for a given term $M$ and typing
% environment $\TEnv$. The principal type for this term can then be given as
% $\forall \many{\alpha}. \Preds \then \tau$ where $\many{\alpha}$ are the type variables that appear
% in $\tau$ but not in $\TEnv$. The type inference algorithm indeed might not always succeed.
% The terms for which the type inference does not succeed are called ill-typed terms.
% Ideally, the ill-typed terms would belong to the category of terms which if run would cause the program to crash.

\newcommand\TAbs{
  \ib{\irule[\trule{t-abs}]
    {\QTyping \Preds {\TEnv, x\co\tau_1} {\Tm} {\tau}};
    {\QTyping \Preds \TEnv {\Lam x {\tau_1} \Tm} {\tau_1 \to \tau}}}
}
 
\newcommand\TApp{
  \ib{\irule[\trule{t-app}]
    {\QTyping \Preds \TEnv {\Tm_1} {\tau_2 \to \tau}}
    {\QTyping \Preds \TEnv {\Tm_2} {\tau_2}};
    {\QTyping \Preds \TEnv {\Tm_1\App\Tm_2} {\tau}}}
}

\newcommand\TLet{\ib{\irule[\trule{t-let}]
  {\QTyping \Preds {\TEnv} {\Tm_1} \tau_1}
  {\sigma = \Gen \TEnv {\Preds\then\tau_1}}
  {\QTyping {\Preds_1} {\TEnv, x\co\sigma} {\Tm_2} \tau_2};
  {\QTyping {\Preds_1} \TEnv {\Let x {\Tm_1} {\Tm_2}} \tau_2}}
}

\newcommand\TVar{
  \ib{\irule[\trule{t-var}]
    {x\co\sigma \in \TEnv}
    {P\then\tau = \Ins{\sigma}};
    {\QTyping \Preds \TEnv x \tau}}
}

\newcommand\TDataIntro{
  \ib{\irule[\trule{\I D}]
    {\many{\QTyping \Preds \TEnv {\Tm_i} {\tau_i}}}
    {D\co{\many{\tau_i}} \to T\many\tau \in \TEnv};
    {\QTyping \Preds \TEnv {D \many{\Tm_i}} {T\many{\tau}}}}}

\newcommand\TDataElem{
  \ib{\irule[\trule{\E D}]
    {\many{\QTyping \Preds \TEnv {\Tm_i} {\tau_i}}\todo{fixme}}
    {D{\many{\tau_i}} \to T\many\tau \in \TEnv};
    {\QTyping \Preds \TEnv {\Case e {\many M}} {\tau}}}
}

\begin{figure}[ht]
  \[
    \begin{array}{c c}
      \TAbs & \TApp\\
      \TVar & \TLet\\
      \TDataIntro & \TDataElem
    \end{array}
  \]
  \caption{Typing judgments for \TCFD{} Terms}
  \label{fig:tcfd-typing}
\end{figure}

\AI{Talk about principal typing scheme?}
%% Ordering relations on Predicates and Types and constraint types.
% To define the notion of principal typing scheme we need to define the notion of comparing two constraint types.
% We first define an ordering on the predicates by the entailment relation denoted by $\entails$.
% By entailment, we mean that if we have finite sets of predicates, say $\Preds$ and $\MorePreds$, and $\Preds$ holds
% whenever $\MorePreds$ holds, then we say $\MorePreds \entails \Preds$ ($\MorePreds$ entails $\Preds$).
% The ordering would be $\MorePreds \leq \Preds$ as $\MorePreds$ is more
% specific than $\Preds$. The entailment relation needs to satisfy three properties:
% (1) reflexivity ($P \entails P$), (2) transitivity
% (if $\Preds_1 \entails \Preds_2$ and $\Preds_2 \entails \Preds_3$ then $\Preds_1 \entails \Preds_3$).
% We can also define ordering on types where we say a type $\tau_1$ is more general than another type $\tau_2$
% if and only if there exists a substitution such that $\tau_1[\many{\alpha}/\many{\beta}] = \tau_2$.
% We can now give an ordering relation to constraint types on the basis of the values it can inhabit.
% We say that a constraint type $\sigma_2$ is more general that $\sigma_1$ if every instance of $\sigma_2$
% is also an instance of $\sigma_1$ and by abuse of notation we say $\sigma_2 \leq \sigma_1$.
% Intuitively, a type is more general if it can inhabit more values.

%% How can one detect inconsistent class instances in the formalization
\subsection{Instance Validity and Inconsistency Detection}
%% How to formalize classes and instances?
Each typeclass declaration introduces a new relation on types in the type system. With functional dependencies
we introduce some additional constraints that the instances should satisfy.
We need to ensure that the instances declared are compatible
with the functional dependencies associated with the typeclass.
There are two necessary conditions to ensure this:
\begin{enumerate}[topsep={0pt},partopsep={0pt}]
\item\emph{Covering Condition}:  For each new instance declaration !instance $\Preds$ => C t where ...!
  that the user writes, we need to check that, for each functional dependency
  $f =$ (!$\many{X}$ -> $\many{Y}$!) $\in \fundep{C}$,
  $\TV{t_Y} \subseteq \closure{\TV{t_X}}{f}$. Consider the class declarations !class C1 a b | a -> b!
  and !class C2 a b | b -> a! and an instance declaration,
  !instance C1 Int x => C2 x Int!. This instance declaration violates the above condition,
  as !x! cannot be determined by the dependency !b -> a!.
  It turns out, that this condition is weak\cite{jones_language_2008}.
  An instance might have additional dependencies induced by the predicates $\Preds$
  that we need to take into account. A more appropriate check would be
  $\TV{t_Y} \subseteq \closure{\TV{t_X}}{\fundep{{P,C}}}$,
  where $\fundep{{P,C}}$ are the functional dependencies of $C$ and additional dependencies
  induced by the instance context $P$. Intuitively, this condition says that
  all the type variables of the determinant, $\TV{t_Y}$, should either already be in the
  set of dependent type variables, $\TV{t_X}$, or should be fully determined using the
  functional dependencies induced by the class ($\fundep{C}$) or induced by the constraints ($\fundep{P}$).
\item\emph{Consistency Condition}: For each new instance of the form !instance $\MorePreds$ => C s where ...!
  along with\newline !instance $\Preds$ => C t where ...! we need to ensure whenever $t_Y = s_Y$ we also have $t_X = s_X$.
  It is straightforward to check this condition. We first find the most general unifier for $t_X$ and $s_X$,
  say $U$, and then check that $U t_Y = U s_Y$. If we cannot find such a unifier, then we know that
  the instances are consistent. For example, !instance C1 Int a! is consistent with !instance C1 Char a!
  as there is no unifier for !Int! and !Char!. However, !instance Add Int Float Float!
  and !instance Add Int Float Int! are inconsistent.
\end{enumerate}
% Are they sufficient?
% The first is to ensure that the instances that the user writes
% are valid and second for each new instance that the user writes, we need to check that it does not
% contradict the functional dependency.

%% what is an improving substitution, how can we compute it?
\subsection{Computing and Using Improving Substitution}\label{subsec:fd-improve}
An improving substitution, written as $\impr\Preds$, is a substitution that does not change the set of
satisfiable instances of predicate set $\Preds$.
Thus, if $\Omega = \impr{P}$ then $\satisfyable{P} = \satisfyable{\Omega P}$. Now, computing
an improving substitution is straightforward with the induced functional
dependencies, $\fundep \Preds$, on the predicate set, $\Preds$.
For each $(\many{X} \to \many{Y})\in\fundep{P}$
whenever we have $\TV{t_X}$ we can infer $\TV{t_Y}$. The rational behind
improving substitution is that it helps simplifying the type by showing its true
and concise characterization. For example, for a given type !Add Int Float p => p!
we know that there is a unique choice for !p! due to the functional dependency,
thus we have an improving substitution $\Omega = [p/Float]$ which
fixes the seemly polymorphic type variable !p! without changing its indented meaning.
Improving substitutions also affects the way ambiguous types are detected. We need to
For a qualified type, $\forall\many{\alpha}.\Preds\then\tau$ the usual ambiguity
check is $(\many{\alpha}\cap\TV{P}) \subseteq \TV{\tau}$. However, with induced functional dependencies $F_P$
due to $\Preds$, the appropriate check would be $(\many{\alpha}\cap\TV{P}) \subseteq \closure {\TV{\tau}} {F_\Preds}$.
We thus weaken the check to ensure that there might be some type variables $\alpha_i$ that are determined by the
functional dependencies due to the class constraints.

\subsection{Type safety of \TCFD{}}\label{subsec:tcfd-safety}
The system that has been described has been in terms of its static semantics.
For the static semantics to be of any real use, We also need to provide an important property
of the system in the spirit of \cite{milner_theory_1978}---``Well typed programs
don't go wrong.''---or if our type system says a program is well typed, then if we run the program,
it should not crash (or get stuck). Before we can formalize type safety, we formalize
what running the program means. We say a term $\Tm$ reduces $\Tm'$ or $\stepsto \Tm {\Tm'}$
using the rules shown in \pref{fig:tcfd-opsem}.
\newcommand\AppR{
  \ib{\irule[\trule{s-app}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\Tm_2} {\Tm'_1\App\Tm_2}}}
}
\newcommand\BetaR{
  \ib{\irule[\trule{s-$\beta$}];
    {\stepsto {(\Lam x \tau \Tm_1)\App\Tm_2} {\Tm_1[x/\Tm_2]}}
  }
}

\begin{figure}[ht]
  \[
    \begin{array}{c c}
      \AppR & \BetaR
    \end{array}
  \]
  \caption[\TCFD Operational Semantics]{Small Step Operational Semantics for \TCFD}
  \label{fig:tcfd-opsem}
\end{figure}


\begin{lemma}[Progress \TCFD{}]\label{lem:tcfd-prog}
  If $\QTyping \empt \empt {\Tm_1} \tau$ then $\Tm_1 \in \Val$ or $\stepsto {\Tm_1} {\Tm_2}$.
\end{lemma}
\begin{lemma}[Preservation \TCFD{}]\label{lem:tcfd-preserve}
  If $\QTyping \empt \empt {\Tm_1} \tau$ and $\stepsto {\Tm_1} {\Tm_2}$ then $\QTyping \empt \empt {\Tm_2} \tau$
\end{lemma}
For preservation, we need to also prove a helper lemma, that says substitution is sound.
\begin{lemma}[Term Substitution \TCFD{}]\label{lem:tcfd-subst}
  If $\QTyping \Preds {\TEnv,x\co\tau_2} {\Tm_1} {\tau_1}$ and $\QTyping \Preds \TEnv {\Tm_2} {\tau_2}$ then
  $\QTyping {\Preds} {\TEnv} {\Tm_1[x/\Tm_2]} \tau_1$
\end{lemma}
We define $\manystepsto {\bullet} {\bullet}$ as a transitive closure of
the $\stepsto{\bullet}{\bullet}$ relation.
The (syntactic) type safety of the system can formally be given as
\begin{lemma}[Type Safety \TCFD{}]
  If $\QTyping \empt \empt \Tm \tau$ and $\manystepsto \Tm {\Tm'}$ then $\Tm' \in \Val$
\end{lemma}


% The idea of functional dependency has been borrowed from the theory of relational
% databases\cite{codd_realtional_1970, amstrong_dependency_1974}. In simple terms,
% an attribute (or a set of attributes) $y$ is said to be dependent
% on another attribute (or a set of attributes) $x$, if in a relation $R$,
% the value (or values) of $x$ uniquely determine the value (or values) of $y$.
% In such a functional dependency, the attribute $y$ is said to be
% the dependent while $x$ is the determinant. To elucidate this analogy
% we use \pref{fig:fd-table}. Each table describes a typeclass
% and its instances. The attributes are typeclass's type parameters.
% Each row is an instance of the typeclass and the set of all the rows in the table
% describe the relation. A slight difference between database tables
% and type class tables is that we can have a table of infinite number
% of rows in the latter but not in the former. In this table form,
% it is easy to see that inconsistent instances arise when we have a duplicate
% row for the determinant fixed by the functional dependency.

% \todo{fix the table column widths using tabularx}
% \begin{figure}[ht]
%   \begin{tabular}[ht]{c c c c}
%     \begin{tabular}[ht]{l}
%       Type class\\
%       \hline
%       FunDeps\\
%       \hline
%       Attributes\\
%       \hline
%       \\
%       Values\\
%       \\
%       \\
%     \end{tabular}&%
%                    \begin{tabular}[ht]{c  c  c}
%                      & Add & \\
%                      \hline
%                      & !m n -> p! &\\
%                      \hline
%                      m & n & p\\
%                      \hline
%                      Int & Int & Int\\
%                      Float & Float & Float\\
%                      Int & Float & Float\\
%                      Float & Int & Float\\
%                    \end{tabular} &%
%                                    \begin{tabular}[ht]{c c c}
%                                      & TEq & \\
%                                      \hline
%                                      !t -> u! && !u -> t!\\
%                                      \hline
%                                      t   && u\\
%                                      \hline
%                                      Int && Int\\
%                                      Z && Z\\
%                                      S Z && S Z \\
%                                      & \ldots  & \\
%                                    \end{tabular}&%
%                                                   \begin{tabular}[ht]{c c c}
%                                                     & Convert & \\
%                                                     \hline
%                                                     \\
%                                                     \hline
%                                                     a   &&  b\\
%                                                     \hline
%                                                     Int && Int\\
%                                                     Int64 && Int64\\
%                                                     Int && Int64\\
%                                                     & \ldots  & \\
%                                                   \end{tabular}
%   \end{tabular}
%   \caption{Class instances as Databases}
%   \label{fig:fd-table}
% \end{figure}



\section{Type Families}\label{sec:tf}
Type family is powerful language feature of describing computation on types in a more
natural style of functional programming rather than relations in the style of logic programming.
For example, we can define addition over the two previously mentioned types !Z! and !S n!
as shown in \pref{fig:plus-ty-fam}. This style is a lot more palpable for programmers
who are already used to writing equations with pattern matching at term level.
It also has a cleaner view and has less code clutter compared to functional dependencies.
The vector concatenation !concat_vec! also gets a cleaner and concise type as compared to previous definitions.

\begin{figure}[ht]
  \begin{tabular}{l l}
\begin{code}
data TT -- Type level True
data FF -- Type level False
\end{code}&%
\begin{code}
type family TEq n m where
  TEq a a = TT
  TEq a b = FF
\end{code}\\
\begin{code}
type family Plus n m where
Plus Z     m = m
Plus (S n) m = S (Plus n m)
\end{code}&%
\begin{code}
concat_vec :: Vec m e -> Vec n e -> Vec (Plus n m) e
concat_vec v1 v2 = $\ldots$
\end{code}
  \end{tabular}
  \caption{Peano Arithmetic and Vector Operations with Closed Type Family}
  \label{fig:plus-ty-fam}
\end{figure}
The !Add m n p! typeclass defined in \pref{fig:add-tc-fd} can also be written in
the type family style as shown in \pref{fig:add-ty-fam}. The change is that the new 
!Add! typeclass takes only two parameters in this setting while the result type
of !(+)! function now returns a special type !Result m n!. This !Result m n! type is defined
for each instance we expect the typeclass !Add! to be defined at.
As expected, the instance !Add Int Float! would raise a type error due to its conflict with
the first type instance. 

Before we go further, we first need to fix the taxonomy of the building blocks of type family declaration.
Taking the example of !Plus m n!, the header---!type family Plus m n!--says that we are
declaring a new type family constructor named !Plus! with an arity 2. The equations
are listed after the !where! keyword. Each equation's left hand side mentions
the name of the type family and a type pattern, and the right hand side mentions the result type.
%The type pattern can be thought of as a tuple which may contain type variables. 

\begin{figure}[ht]
  \begin{tabular}{l l}
\begin{code}
type family Result m n where
  Result Int Int = Int   -- (1)
  Result a Float = Float -- (2)
  Result Float a = Float -- (3)

class Add m n where
  (+) :: m -> n -> Result m n

instance Add Int Int where
  (+) = intAdd
\end{code}&%
\begin{code}
instance Add Int Float where
  i + f = addFloat (int2Float i) f

instance Add Float Int where
  f + i = addFloat (int2Float i) f

instance Add Int Float where -- Error
  i + f = addInt i (float2int f)
    \end{code}
  \end{tabular}
  \caption{\texttt{Add} Typeclass using Closed Type Family}
  \label{fig:add-ty-fam}
\end{figure}
The system that supports closed type families (\CLTF{}), is an extension of \FC\cite{sulzmann_system_2007}.
\FC is essentially System F\cite{girard_proofs_1989,reynolds_towards_1974} with type equality coercions.
A notable feature of GHC, an implementation of Haskell, is that it compiles the surface language
to an explicitly type annotated core language based on \FC. The program transformation
passes done after type checking also produce well typed \FC terms. The surface level expression
language for GHC is close to Hindley-Milner language which may not mention any types or coercions.
All the coercions thus have to be inferred by the type checker while compiling
the source language into to core language. 

\subsection{Closed Type Families}\label{subsec:tf-closed}
The closedness of type families comes from the fact that the programmer cannot add any more equations once they
are defined. But as evident from the !TEq! example, they can very well be used for any new types
that may subsequently be defined without any issues. 
The utility of closed type families is further elucidated with the examples
given in \pref{fig:tf-closed-examples}. !CountArgs! computes the number of arguments that a type expects while the
!TMember! can be used to check if a given type exists in a complex type data structure.
The key take away is that closed type families make it easier to define functions on types
that would otherwise need some complex encoding that would require a type checker
which supports backtracking.
\begin{figure}[ht]
  \begin{tabular}{l l}
\begin{code}
data Leaf a
data Node a b
\end{code}&%
\begin{code}
type family Or a b where
  Or FF a = a
  Or TT a = TT
  Or a TT = TT
\end{code}\\
\begin{code}
type family TMember e tree where
  TMember e (Leaf e') = TEq e e'
  TMember e (Node lt rt) = Or (TMember e lt) (TMember e rt)
\end{code}&%
\begin{code}
type family CountArgs ty where
  CountArgs (a -> b) = S (CountArgs b)
  CountArgs b        = Z
\end{code}
  \end{tabular}
  \caption{Complex Typelevel Functions}
  \label{fig:tf-closed-examples}
\end{figure}

Intuitively, the semantics of type family declarations is to lift the type family equations into axioms.
Instantiating one of these axiom would give us coercions which can be
used as an evidence for equality between two types. We say that a target type $\tau$
reduces to or evaluates to another type $\tau_1$ when we can
find such an evidence. We say a rule is fired when a certain type family rule is used
to generate a coercion evidence term. For example, the target type !Int -> Float -> Result Int Float!
reduces to or evaluates to !Int -> Float -> Float! with the rule !Result a Float = Float! being fired.
before we dive into the formalization of this system, there are some subtle details about
the static semantics of type reduction that we ought to mention informally as we need the system to be consistent.

The type rewriting is performed by using a top to bottom target matching procedure,
where the first instance of the left hand side that matches is used to rewrite the type.
This enables the type equations to possibly have have overlapping left hand sides of the equations.  
The type family definition of !TEq a b! indeed has overlapping equations with !Eq a a! and !Eq a b!.
The type !TEq a a! is non-linear as it mentions the type variable !a! twice.
Overlapping equations and non linear patterns introduce some complexity in the system, but it also
enhances usability. There are two restrictions on the type patterns
(1) it should  have the same length as the arity of the type family constructor, and
(2) the type patterns can not have occurrences of type family constructors.
The first condition is necessary to avoid having partially applied type families in our system,
while the second condition is to ensure confluence.

Consider !BadTyFam! shown in \pref{fig:closed-tf-bad}, and a target type
!BadTyFam (TEq Int Bool)!. The last equation is fired in this case and we reduce targe to !FF!.
However, if we instead evaluate !TEq Int Bool! first we get !TT! and the second equation fires.
This is problamatic. We also need to avoid eager target type reduction as shown with the !boom! example,
that will case a crash at runtime. The crux of the problem is that, if we (erroneously) reduce
!TyFam (TEq Bool d)! we get !()!, as !TEq Bool d! matches the second equation from !TEq a b!,
and it reduces to !FF!. However, in the call to !boom!, we see that !d! is instantiated with !Bool!
thus !TyFam (TEq Bool d)! it should reduce to !Int -> Int!. This is indeed, unsound.
\begin{figure}[ht]
  \begin{tabular}{l l}
\begin{code}
type family BadTyFam a where
  BadTyFam TT        = FF
  BadTyFam FF        = TT
  BadTyFam (TEq x y) = FF
type family TyFam b where
  TyFam TT = Int -> Int
  TyFam FF = ()
\end{code}&%
\begin{code}
fun :: d -> TyFam (TEq Bool d)
fun _ = ()
boom :: Int
boom = fun True 5 -- $\text{\faBomb}$
\end{code}
  \end{tabular}
  \caption{Bad Type Families}
  \label{fig:closed-tf-bad}
\end{figure}
A na\"ive notion of matching where we check for failure for a most general unifier of two types
is not a fool proof mechanism as it can lead to non-confluence and inconsistency in presence of type families.
We instead use the following definition of apartness using type flattening defined below:\todo{space hack here}
\begin{definition}[Type Flattening]\label{def:ctf-flatten}
  We say a type $\tau$ is flattened to $\tau_1$, or $\tau_1 = \flatten{\tau}$, when every
  type family application of the from $\FamCtrs(\many\sigma)$ is replaced by a type variable,
  such that in the flattened type, every syntactically equivalent type family application
  in $\tau$ is replaced by same type fresh type variable and syntactically different type family applications in $\tau$
  are replaced by distinct fresh type variables.

  For example, if we have a type !$\tau$ = F b c -> F a b -> F a b -> F c b!
  then $\flatten\tau =$!$\alpha_1$ -> $\alpha_2$ -> $\alpha_2$ -> $\beta$!
  with $[\alpha_1/\texttt{F b c}, \alpha_2/\texttt{F a b}, \beta/\texttt{F c b}]$.
\end{definition}
Now apartness of types and dually matching can be defined as:
\begin{definition}[Apart and Matching]\label{def:apart-match-ty}
  We say two types, $\tau_1$ and $\tau_2$ are apart if $\mgu{\tau_1}{\flatten{\tau_2}}\fails$ and $\tau_1$ does not
  mention type family constructors and dually, $\match{\tau_1}{\tau_2} = \lnot\apart{\tau_1}{\tau_2}$
\end{definition}
Simplification of type families just by using apartness criterion is too restrictive,
for example if the two equations simplify to the
same right hand side every time they have have matching left hand sides,
they are sound and we should allow them. For example, see first and third equation in
!Or a b! example in \pref{fig:tf-closed-examples}.
We formalize the notion of compatibility of equations below:
\begin{definition}[Compatible Equations]\label{def:compact-eq}
  The two equations, $p$ and $q$, are compatible
  if there exist two substitutions, $\Subst_1$ and $\Subst_2$ such that
  if $\Subst_1(\lhs{p}) = \Subst_2(\lhs{q})$ then $\Subst_1(\rhs{p}) = \Subst_2(\rhs{q})$.
\end{definition}
Implementing compatibility is simple. For two equations $p$ and $q$, we find $\Subst = \mgu{\lhs p, \lhs q}$.
If the call to unification fails, then the equations are compatible vacuously else if we do find a substitution,
we check if $\Subst\rhs p = \Subst\rhs q$. 
\begin{definition}[Closed Type Family Simplification]\label{def:cft-simpl}
  An equation, say $p$, given in the type family declaration can be used to simplify the the
  target $\FamCtrs(\many\tau)$ to a type if the following two conditions hold:
  \begin{enumerate}
  \item The type pattern on left hand side of the equation, $\FamPattern_p$ matches with the
    target $\many\tau$ or $\match{\FamPattern_p}{\many\tau}$
  \item Any equation $q$, that precedes $p$, is either compatible with $p$, $\compat p q$,
    or it's pattern $\FamPattern_q$ is apart, $\apart {\FamPattern_q} {\many\tau}$.
  \end{enumerate}
\end{definition}

\subsection{Formalizing Closed Type Families}\label{subsec:tf-closed-formal}

\begin{figure}[ht]
  \[
    \begin{array}{l l l}
      &\text{Type family Constructors} &\texttt{\FamCtrs}\\
      &\text{Type Constructors} &\texttt{\TypeCtrs}\\      
      \\
      &\text{Type Validity}               &\ValidType \TEnv \tau\\
      &\text{Proposition Validity}        &\ValidProp \TEnv \Preds\\
      &\text{Ground Context Validity}     &\GCtxValid{\GEnv}\\
      &\text{Variable Context Validity}   &\VCtxValid\GEnv\VEnv\\
      &\text{Context Validity}            &\CtxValid\TEnv\\
      \\
      &\text{Term Typing}              &\Typing \TEnv \Tm \tau\\
      &\text{Coercion Typing}          &\CoTyping \TEnv \Co \Preds\\
      \\
      &\text{One Hole Type Context}    &\TEvalCtxt{\bullet}
    \end{array}
    \begin{array}{l l l l l}
      &\text{Types}           &\tau,\sigma  &\bnfeq \alpha \bnfor \tau\to\tau \bnfor \Forall\alpha\tau
                                              \bnfor \FamCtrs(\many\tau) \bnfor \TypeCtrs(\many\tau)&\\
      &\text{Ground Types}    &\GTy         &\bnfeq \tau\to\tau \bnfor \Forall\alpha\tau \bnfor \TypeCtrs\many\tau\\
      &\text{Predicates}      &\Preds       &\bnfeq \tau\teq\tau\\
      &\text{Type family Pattern}     &\texttt{\FamPattern} &\bnfeq \many\tau\\
      &\text{Axiom Equations} &\AxiomEq     &\bnfeq \Forall{\many\alpha}{\FamCtrs(\FamPattern) \teq \sigma}\\
      &\text{Axiom Types}     &\AxiomTy     &\bnfeq \many\AxiomEq\\
      &\text{Coercions}  &\Co,\MoreCo &\bnfeq \Co\to\MoreCo \bnfor \Forall\alpha\Co \bnfor \Co@\tau
                                        \bnfor \FamCtrs(\many{\Co})\bnfor \nth i \Co\\
      &                  &            &\bnfor \refl\tau \bnfor \sym{\Co} \bnfor \comp\Co\MoreCo
                                        \bnfor \branch{i}{\many\tau} & \\
      \\
      &\text{Ground Context} &\GEnv   &\bnfeq \empt \bnfor \GEnv,\branch{}{}:\AxiomTy
                                        \bnfor \GEnv,\FamCtrs:n \bnfor \GEnv,\TypeCtrs:n\\
      &\text{Variable Context}&\VEnv  &\bnfeq \empt \bnfor \VEnv,x\co\tau \bnfor \VEnv,\alpha\\
      &\text{Typing Context}  &\TEnv  &\bnfeq \GEnv;\VEnv\\
      \\
      &\text{Terms}      & \Tm        &\bnfeq x \bnfor \Lam x \tau \Tm \bnfor \Tm\App\Tm \bnfor\cast M \Co 
                                        \bnfor \TLam \alpha \Tm \bnfor \Tm\App\tau  \\
      &                  &            & \bnfor \DataCtrs\many{e} \bnfor \Case e \many{\Ptrns} \\
      &\text{Type family Declaration} & & \texttt{\textbf{type family}}~
                                          \FamCtrs\App\many{\alpha}\texttt{\textbf{ where }}
                                          \many{F\App\FamPattern = \tau}
    \end{array}
  \]
  \caption[\CLTF{}]{System for Closed Type Families}
  \label{fig:syntax-tf-closed}
\end{figure}
As the surface level language for GHC is too big to formalize, we will formalize a small portion
of interesting language constructs. The \CLTF{}, has coercion types and 
a type family constructors which are different from type constructors as they differ in their
static semantics. The type family constructor is brought in scope using the !type family! keyword.
The equations after the keyword !where! defines the list of axioms for the type family reductions.
For example, the axiom equations for !TEq! type family looks like
$\texttt{axiomTEq}: [\forall\alpha.~{\texttt{TEq}~\alpha~\alpha} \teq \texttt{TT}, \forall\alpha\beta.~{\texttt{TEq}~\alpha~\beta} \teq \texttt{FF}]$.

% Type equality coercions are special types, that are proofs
% for equality between types. The type coercion $\gamma:\tau_1\teq\tau_2$
% says that type $\tau_1$ is equivalent to type $\tau_2$. These type coercions
% are the workhorse of type rewriting, an essential component of functions at
% type level.


The typing judgments for terms in this system is a quadruple $\Typing\TEnv\Tm\tau$ that asserts that
there is a derivation such that term $\Tm$ has type $\tau$ under the typing context $\TEnv$. All the interesting
rules are given in \pref{fig:tf-closed-typing}. The typing environment ($\TEnv$) consists of two contexts,
the variable context ($\VEnv$) which maps free variables to their types, and ground context ($\GEnv$)
that stores all the type rewriting axioms and also necessary information for type and family constructors.
The type validity judgments along with ground context and variable context validity are given in \pref{fig:tf-closed-validity-js}.
They are essentially walking over the context structures and ensuring we do not add anything invalid.

\newcommand\ValidTyVar{
  \ib{\irule[\trule{v-tvar}]
    {\alpha\in \VEnv}
    {\CtxValid{\GEnv;\TEnv}};
    {\ValidType{\GEnv;\VEnv}\alpha}
  }
}
\newcommand\ValidTyCtr{
  \ib{\irule[\trule{v-tctr}]
    {\TypeCtrs \co n \in \GEnv}
    {\CtxValid{\GEnv;\TEnv}}
    {\many{\ValidType{\GEnv;\VEnv}{\tau_i}}^{i<n}};
    {\ValidType {\GEnv;\VEnv}{\TypeCtrs\many\tau}}
  }
}
\newcommand\ValidTFCtr{
  \ib{\irule[\trule{v-tfctr}]
    {\FamCtrs \co n \in \GEnv}
    {\CtxValid{\GEnv;\TEnv}}
    {\many{\ValidType{\GEnv;\VEnv}{\tau_i}}^{i<n}};
    {\ValidType {\GEnv;\VEnv}{\FamCtrs\many\tau}}
  }
}
\newcommand\ValidTyArrow{
  \ib{\irule[\trule{v-arr}]
    {\ValidType \TEnv \tau_1}
    {\ValidType \TEnv \tau_2};
    {\ValidType {\TEnv}{(\tau_1\to\tau_2)}}
  }
}
\newcommand\ValidTyFA{
  \ib{\irule[\trule{v-tfa}]
    {\ValidType {\GEnv;\VEnv,\alpha} \tau};
    {\ValidType {\GEnv;\VEnv}{(\Forall\alpha\tau)}}
  }
}

\newcommand\ValidEqProp{
  \ib{\irule[\trule{v-eqp}]
    {\ValidType \TEnv {\tau_1}}
    {\ValidType \TEnv {\tau_2}};
    {\ValidProp \TEnv {\tau_1\teq\tau_2}}
  }
}
\newcommand\ValidTyFamProp{
  \ib{\irule[\trule{v-tfp}]
    {\FamCtrs\co n \in \GEnv}
    {\many{\ValidType {\GEnv;\VEnv} \tau_i}^{i<n}}
    {\ValidType \TEnv \sigma};
    {\ValidProp {\GEnv;\VEnv} {\FamCtrs\many\tau \teq \sigma}}
  }
}

\newcommand\ValidGndContextEmpt{
  \ib{\irule[\trule{v-gempt}];
    {\GCtxValid\empt}
  }
}
\newcommand\ValidGndContextTF{
  \ib{\irule[\trule{v-gtf}]
    {\fresh \FamCtrs \GEnv}
    {\GCtxValid\GEnv};
    {\GCtxValid{\GEnv,\FamCtrs \co n}}
  }
}
\newcommand\ValidGndContextTC{
  \ib{\irule[\trule{v-gtc}]
    {\fresh \TypeCtrs \GEnv}
    {\GCtxValid\GEnv};
    {\GCtxValid{\GEnv,\TypeCtrs \co n}}
  }
}

\newcommand\ValidGndContextAxiom{
  \ib{\irule[\trule{v-gax}]
    {\substack {\GCtxValid\GEnv\\
               \fresh {\branch{}{}}\GEnv}}
    {\substack {\many{\ValidType {\GEnv;\many{\alpha}_i} {N_i}}^{i<n}\\
                \many{\ValidType {\GEnv;\many{\alpha}_i} {\sigma_i}}^{i<n}}};
    {\GCtxValid{\GEnv,\branch{}{}\co\many{\Forall{\many\alpha}{\FamCtrs(\FamPattern)\teq\sigma}}}}
  }
}

\newcommand\ValidVCtxtEmpt{
    \ib{\irule[\trule{v-vempt}]
    {\GCtxValid\GEnv};
    {\VCtxValid\GEnv\empt}
  }
}
\newcommand\ValidVCtxtTVar{
  \ib{\irule[\trule{v-tyvar}]
    {\VCtxValid\GEnv\VEnv}
    {\fresh\alpha\VEnv};    
    {\VCtxValid\GEnv{\VEnv,\alpha}}
  }  
}
\newcommand\ValidVCtxtVar{
  \ib{\irule[\trule{v-var}]
    {\VCtxValid\GEnv\VEnv}
    {\fresh x \VEnv}
    {\ValidType{\GEnv;\VEnv}\tau};
    {\VCtxValid{\GEnv}{\VEnv,x\co\tau}}
  }    
}

\newcommand\ValidTyCtx{
  \ib{\irule[\trule{v-te}]
    {\VCtxValid\GEnv\VEnv};
    {\CtxValid{\GEnv;\VEnv}}
  }
}

\begin{figure}[ht]
  \[
    \begin{array}{c c c}
      \ValidTyVar & \ValidTyArrow & \ValidTyFA\\
    \end{array}
  \]
  \[
    \begin{array}{l l}
      \ValidTyCtr & \ValidTFCtr\\      
    \end{array}
  \]
  \[
    \begin{array}{c c}
      \ValidEqProp & \ValidTyFamProp
    \end{array}
  \]
  \[
    \begin{array}{c c c c}
      \ValidGndContextEmpt & \ValidGndContextTC & \ValidGndContextTF & \ValidGndContextAxiom
    \end{array}
  \]
  \[
    \begin{array}{c c c c}
      \ValidVCtxtEmpt & \ValidVCtxtVar & \ValidVCtxtTVar & \ValidTyCtx
    \end{array}    
  \]
  \caption{Validity Judgments}
  \label{fig:tf-closed-validity-js}
\end{figure}


The ground context is ideally ambient for all typing rules.
The term typing rules are standard and we skip them due to space constraints except, the three interesting
ones. As \CLTF{} is based on System F we have two rules at term level, one for
type abstraction $\trule{t-tyabs}$ and another for type application $\trule{t-tyapp}$. These
rules are similar to previously described $\trule{t-abs}$ and $\trule{t-app}$ respectively, but the arguments
are types instead of terms. The rule $\trule{t-cast}$ which is important
for our discussion says that a term can be typed using a new type if there is a welltyped witness $\Co$,
that says it is okay to do so.
The three rules $\trule{co-refl}$, $\trule{co-sym}$, and $\trule{co-trans}$ say that the
coercions form an equivalence relation. The four rules $\trule{co-arr}$, $\trule{co-type}$,
$\trule{co-forall}$ and $\trule{co-fam}$ says that if two types are equal then each of
their respective components are also equal, or that they form a congruence relation. The rules $\trule{co-ntharr}$ and
$\trule{co-nth}$ says that we can decompose type qualities into simpler ones. The rule $\trule{co-inst}$
says that if we have a witness that says two polytypes are equal, then we can obtain a witness where their respective
instantiations with a type are also equal types.

\newcommand\TCast{
  \ib{\irule[\trule{t-cast}]
    {\CoTyping \TEnv \Co {\tau_1\teq\tau_2}}
    {\Typing \TEnv \Tm \tau_1};
    {\Typing \TEnv \Tm \tau_2}}}

\newcommand\TTyAbs{
  \ib{\irule[\trule{t-tyabs}]
    {\ValidType \TEnv \alpha}
    {\Typing {\TEnv,\alpha} \Tm \tau};
    {\Typing \TEnv {\TLam\alpha\Tm} {\Forall\alpha\tau}}}}

\newcommand\TTyApp{
  \ib{\irule[\trule{t-tyapp}]
    {\ValidType \TEnv {\tau_1}}
    {\Typing \TEnv \Tm {\Forall\alpha\tau}};
    {\Typing \TEnv {\Tm\App\tau_1} \tau[\tau_1/\alpha]}}}


\newcommand\CoArr{
  \ib{\irule[\trule{co-arr}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \sigma_1}}
    {\CoTyping \TEnv \MoreCo {\tau_2 \teq \sigma_2}};
    {\CoTyping \TEnv {\Co\to\MoreCo} {(\tau_1\to\tau_2) \teq (\sigma_1\to\sigma_2)}}}}

\newcommand\CoNthArr{
  \ib{\irule[\trule{co-ntharr$_i$}]
    {\CoTyping \TEnv \Co {(\tau_1\to\tau_2) \teq (\sigma_1\to\sigma_2)}};
    {\CoTyping \TEnv {\nth i \Co} {\tau_i \teq \sigma_i}}}}

\newcommand\CoForall{
  \ib{\irule[\trule{co-forall}]
    {\CoTyping {\TEnv,\alpha} \Co {\tau_1 \teq \tau_2}};
    {\CoTyping \TEnv {\Forall\alpha\Co} {(\Forall\alpha\tau_1) \teq (\Forall\alpha\tau_2)}}}}

\newcommand\CoInst{
  \ib{\irule[\trule{co-inst}]
    {\ValidType\TEnv\tau}
    {\CoTyping {\TEnv} \Co {\Forall\alpha\sigma_1 \teq \Forall\alpha\sigma_2}};
    {\CoTyping \TEnv {\Co@\tau} {\sigma_1[\alpha/\tau] \teq \sigma_2[\alpha/\tau]}}}}
   
\newcommand\CoRefl{
  \ib{\irule[\trule{co-refl}]
    {\ValidType\TEnv\tau};
    {\CoTyping \TEnv {\refl{\tau}}:\tau\teq\tau}}}

\newcommand\CoSym{
  \ib{\irule[\trule{co-sym}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \tau_2}};
    {\CoTyping \TEnv {\sym{\Co}} {\tau_2\teq\tau_1}}}}

\newcommand\CoTrans{
  \ib{\irule[\trule{co-trans}]
    {\CoTyping \TEnv \Co {\tau_1 \teq \tau_2}}
    {\CoTyping \TEnv \MoreCo {\tau_2 \teq \tau_3}};
    {\CoTyping \TEnv {\comp \Co \MoreCo} \tau_1\teq\tau_3}}}

\newcommand\CoNth{
  \ib{\irule[\trule{co-nth}]
    {\CoTyping \TEnv \Co {\TypeCtrs\many\tau \teq \TypeCtrs\many\sigma}};
    {\CoTyping \TEnv {\nth i {\Co}} {\tau_i\teq\sigma_i}}}}

\newcommand\CoTypeCtr{
  \ib{\irule[\trule{co-type}]
    {\TypeCtrs\co n \in \GEnv}
    {\many{\CoTyping {\GEnv;\VEnv} {\Co_i} {\tau_i \teq \sigma_i}}^{i<n}};
    {\CoTyping {\GEnv;\VEnv} {\TypeCtrs\many\Co} {\TypeCtrs\many\tau \teq \TypeCtrs\many\sigma}}}}

\newcommand\CoFam{
  \ib{\irule[\trule{co-fam}]
    {\FamCtrs\co n \in \GEnv}
    {\many{\CoTyping {\GEnv;\VEnv} {\Co_i} {\tau_i \teq \sigma_i}}^{i<n}};
    {\CoTyping {\GEnv;\VEnv} {\FamCtrs\many\Co} {\FamCtrs\many\tau \teq \FamCtrs\many\sigma}}}}

\newcommand\CoAxiom{
  \ib{\irule[\trule{co-axiom}]
    {\substack {\AxiomTy = \many{\Forall{\many\alpha}{\FamCtrs(\FamPattern) \teq \sigma}}\\
               \branch{}{}:{\AxiomTy} \in \GEnv}}
    {\substack {\many{\ValidType{\GEnv;\VEnv}{\tau_i}} \\
        \forall j < i.~ \nc {\AxiomTy} {i} {\many\tau} {j}}};
    {\CoTyping {\GEnv;\VEnv} {\branch i {\many\tau}} {\FamCtrs (\FamPattern\many{[\alpha_i/\tau_i]}) \teq \sigma\many{[\alpha_i/\tau_i]}}}}}

\begin{figure}[ht]
  \[
    \begin{array}{c c c}
    \TCast   & \TTyAbs & \TTyApp
    \end{array}
  \]
  \[  
    \begin{array}{c c c}
      \CoRefl & \CoSym & \CoTrans
    \end{array}
  \]
  \[
    \begin{array}{c c}
      \CoArr     & \CoNthArr\\      
      \CoTypeCtr & \CoNth\\
      \CoForall  & \CoInst\\
      \CoFam     & \CoAxiom
    \end{array}
  \]
  \caption[Typing Judgments for \CLTF{}]{Typing Judgments \CLTF{}}
  \label{fig:tf-closed-typing}
\end{figure}

The most interesting rule is the behemoth, $\trule{co-axiom}$ which gives conditions as to
when we can use a particular coercion axiom to rewrite a type. In our example of !TEq!, there are two possible
ways in which the axiom could have been instantiated:
$\texttt{TEq}[0][\alpha/\texttt{Int}]: \texttt{TEq  Int Int} \teq \texttt{TT}$
or $\texttt{axiomTEq}[1][\alpha/\texttt{Int}, \beta/\texttt{Int}]: \texttt{TEq Int Int} \teq \texttt{FF}$. But the second
option would make the system unsound. The \noconflict{} check saves us from this disaster
by allowing only the first option and rejecting the second.
The \noconflict{} property is dependent on the equations rather than types used for instantiations.
There are two ways in which the equations are in not in conflict,
1) either the equations are compatible or 2) the equations are apart. The rules are shown in \pref{fig:tf-closed-nc}

\newcommand\NcApart{
  \ib{\irule[\trule{nc-apart}]
    {\AxiomTy = \many{\FamCtrs(\FamPattern) \teq \sigma}}
    {\apart{\FamPattern_j}{\FamPattern_i[\many\tau/\many\alpha_i]}};
    {\nc \AxiomTy i {\many\tau} j}}
}
\newcommand\NcCompt{
  \ib{\irule[\trule{nc-compt}]
    {\compat {\AxiomTy[i]}{\AxiomTy[j]}};
    {\nc \AxiomTy i {\many\tau} j}}
}
\newcommand\CompatInc{
  \ib{\irule[\trule{compt-inc}]
    {\substack {\AxiomEq_1 = \FamCtrs(\FamPattern_1) \teq \sigma_1\\
        {\AxiomEq_2 = \FamCtrs(\FamPattern_2) \teq \sigma_2}}}
    {\Subst = \mgu{\FamPattern_1}{\FamPattern_2}}
    {\Subst\sigma_1 = \Subst\sigma_2};
    {\compat{\AxiomEq_1}{\AxiomEq_2}}}
}
\newcommand\CompatDist{
  \ib{\irule[\trule{compt-dis}]
    {\substack {\AxiomEq_1 = \FamCtrs(\FamPattern_1) \teq \sigma_1\\
        {\AxiomEq_2 = \FamCtrs(\FamPattern_2) \teq \sigma_2}}}
    {\Subst = \mgu{\FamPattern_1}{\FamPattern_2}\fails};
    {\compat{\AxiomEq_1}{\AxiomEq_2}}}
}
\begin{figure}[ht]
  \[
    \begin{array}{c c}
      \NcApart & \CompatDist\\
       \NcCompt & \CompatInc
    \end{array}
  \]  
  \caption{Non Conflicting Equations and Compatibility}
  \label{fig:tf-closed-nc}
\end{figure}

\newcommand\TypeRed{
  \ib{\irule[\trule{ty-red}]
    {\substack{\branch{}{}:\AxiomTy\in\GEnv\\\GCtxValid\GEnv}}
    {\substack{\AxiomTy = \many{\Forall{\many\alpha}\FamCtrs(\FamPattern) \teq \sigma}\\ \forall j < i. ~\nc \AxiomTy i {\many\tau} j}}
    {\substack{\Subst=\mgu {N_i}{\many\tau}\\\tau_1 = \Subst\sigma_i}};
    {\tystepsto \GEnv {\TEvalCtxt{\FamCtrs(\many\tau)}} {\TEvalCtxt{\tau_1}}} }
}


\subsubsection{Type Reduction}
We can formally specify type reduction or rewrite rule, written as $\tystepsto\TEnv\bullet\bullet$, using
the rule $\trule{ty-red}$. This rule says that the $i$-th equation of axiom $\Axiom$,
$\Forall{\many\alpha}{\FamCtrs(\FamPattern_i) \teq \sigma_i}$ is used to reduce
the target type $\FamCtrs(\many\tau)$ to type $\tau_1$. The use of $\TEvalCtxt\bullet$ is to mean
that the rewrite can happen anywhere within the type.
$$
\TypeRed
$$


\subsubsection{Consistency and Goodness of Context}\label{subsec:tf-closed-consistency}
Consistency means that we can never derive unsound equalities between ground types,
such as $\Co:\texttt{Int}\teq\texttt{Bool}$, in the system. Ground types ($\GTy$), in our system are
nothing but $\TypeCtrs\many\tau$, $\tau_1\to\tau_2$ and $\Forall\alpha\tau$.
% Consistency condition is necessary for our system to have progress property. 
We say that a ground context $\GEnv$ is consistent, when for all coercions $\Co$
such that $\CoTyping {\GEnv;\empt} {\Co} {\GTy_1 \teq \GTy_2}$ we have the following:
\begin{enumerate}
\item if $\GTy_1$ is of the form $\TypeCtrs\many\tau$ then so is $\GTy_2$
\item if $\GTy_1$ is of the form $\tau_1\to\tau_2$ then so is $\GTy_2$
\item if $\GTy_1$ is of the form $\Forall\alpha\tau$ then so is $\GTy_2$
\end{enumerate}
In general context consistency is difficult to prove. We take a conservative approach
and enforce syntactic restrictions on the ground context.
\begin{property}[$\Good~\GEnv$]
  A ground context ($\GEnv$) is $\Good$, written $\Good\GEnv$ when
  the following conditions are met for all $\branch{}{}:\AxiomTy\in\GEnv$ and
  where $\AxiomTy$ is of the form $\many{\Forall{\many\alpha}\FamCtrs(\FamPattern)\teq\sigma}$:
  \begin{enumerate}
  \item None of the $\FamPattern_i$ mentions a type family constructor.
  \item The binding variables $\many\alpha$ occur atleast once in $\FamPattern$ on the left hand side of the equation.
  \item If the axiom has multiple equations then, there should be no more than one $\branch{}{}$
    in the context that mentions axioms for a fixed family constructor.
  \item If the axiom has only one equation, say $\AxiomTy$ is of the form $\AxiomEq_1$,
    and there exists another axiom in the context
    also with one equation $\AxiomEq_2$ that also mentions the same type family constructor, then
    it should be the case that $\compat{\AxiomEq_1}{\AxiomEq_2}$.
  \end{enumerate}
\end{property}
Given our characterization of type reduction in the previous section, we now have to show
that if we have $\Good\GEnv$ then, $\GEnv$ is consistent. One way to prove this is
via confuence of type reduction relation. Thus, whenever we have $\tystepsto \GEnv {\tau_1} {\tau_2}$
then we would know that $\tau_1$ and $\tau_2$ have a common reduct, say $\tau_3$. As type reduction
relation $\trule{ty-red}$ only works on type family's and does not touch any ground type heads,
we can prove consistency. However, to prove confluence, it is necessary to assume
termination of type reduction. Thus we get our consistency lemma as given below:
\begin{lemma}[Consistency]
  If $\tystepsto \GEnv \bullet \bullet$ is terminating and $\Good\GEnv$ then $\GEnv$ is consistent.
\end{lemma}

\subsection{Type safety of \CLTF{}}\label{subsec:tf-closed-safety}
\newcommand\SApp{
  \ib{\irule[\trule{s-app}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\Tm_2} {\Tm'_1\App\Tm_2}}}
}
\newcommand\STApp{
  \ib{\irule[\trule{s-tapp}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\tau} {\Tm'_1\App\tau}}}
}

\newcommand\SCApp{
  \ib{\irule[\trule{s-capp}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\Tm_1\App\Co} {\Tm'_1\App\Co}}}
}

\newcommand\SCast{
  \ib{\irule[\trule{s-cast}]
    {\stepsto {\Tm_1} {\Tm'_1}};
    {\stepsto {\cast{\Tm_1}\Co} {\cast{\Tm'_1}\Co}}}
}

\newcommand\SBeta{
  \ib{\irule[\trule{s-$\beta$}];
    {\stepsto {(\Lam x \tau \Tm_1)\App\Tm_2} {\Tm_1[x/\Tm_2]}}
  }
}
\newcommand\STBeta{
  \ib{\irule[\trule{s-T$\beta$}];
    {\stepsto {(\TLam \alpha \Tm)\App\tau} {\Tm[\alpha/\tau]}}
  }
}

\newcommand\SPush{
  \ib{\irule[\trule{s-push}]
    {\Co_1 = \sym{\nth 0 \Co}}
    {\Co_2 = \nth 1 \Co};
    {\stepsto {(\cast {\Lam x \tau \Tm} \Co) \App \Tm_1} {\cast {(\Lam x \tau \Tm)\App(\cast{\Tm_1} {\Co_1})} {\Co_2}}}
  }
}
\newcommand\STPush{
  \ib{\irule[\trule{s-tpush}];
    {\stepsto {(\cast {\TLam \alpha \Tm} \Co) \App \tau} {\cast {(\TLam \alpha \Tm)\App\tau} {\Co@\tau}}}
  }
}
\newcommand\STrans{
  \ib{\irule[\trule{s-trans}];
    {\stepsto {\cast {(\cast \Tm \Co)} \MoreCo} {\cast \Tm {\comp\Co\MoreCo}}}
  }
  
}

As our system has a variety of new terms, we give a new definition
of the $\stepsto \bullet \bullet$ relation using the rules given in \pref{fig:tf-closed-steps}.

\begin{figure}[ht]
  \[
    \begin{array}{c c c c}
      \SApp & \STApp & \SCApp & \SCast
    \end{array}
  \]
  \[
    \begin{array}{c c c}
      \SBeta & \STBeta & \STrans
    \end{array}
  \]
  \[
    \begin{array}{c c}
      \SPush & \STPush
    \end{array}
  \]  
  \caption{Small Step Operational Semantics \CLTF}
  \label{fig:tf-closed-steps}
\end{figure}

Similar to the previous \pref{subsec:tcfd-safety}, we should have type safety for \CLTF which
includes proving preservation and progress.

For proving preservation lemma, we would have to prove term substitution lemma which in turn
will require that substitutions in coercions are sound. This is given by coercion substitution lemma.
\begin{lemma}[Coercion Substitution]\label{lem:coercion-subst}
  If $\CoTyping {\GEnv;\VEnv,\alpha,\VEnv'} {\Co} {\Preds}$ and $\ValidType {\GEnv;\VEnv} \tau$
  then, $\CoTyping {\GEnv;\VEnv,\VEnv} {\Co[\alpha/\tau]} {\Preds[\alpha/\tau]}$
\end{lemma}
The most interesting case would be to prove $\trule{c-axiom}$ case, but the restrictions
due to \noconflict will be enough.

To state progress, it is necessary to show consistency and assume termination of type reduction.
We then get our progress lemma as
\begin{lemma}[Progress \CLTF]
  If $\Typing \empt \Tm \tau$ then either $\Tm$ is a value,
  or $\Tm$ is a coerced value of the form $\cast {\Tm'} \Co$ where $\Tm'\in\Val$
  or there exists a $\Tm_1$ such that $\stepsto \Tm {\Tm_1}$.
\end{lemma}



\subsection{Constraint Type families}\label{subsec:tf-constrained}
In the previous section for closed type families, we have made an implicit assumption---
the type families are all total, in the sense their domain is all the types.
But what about the case where a closed type family is not defined for particular instance?
For example consider the closed type family shown in \pref{fig:incomplete-tyfam}. We know that !PTyFam Bool!
has no satisfying equations associated with it and never will in the future.
In our current setup a program that diverges can be given this nonsensical type.

\begin{figure}[ht]
  \begin{tabular}{l l}
    \begin{code}
      type family PTyFam a where
          PTyFam Int = Bool
    \end{code}&%
    \begin{code}
      pty :: PTyFam Bool -- OK?
      pty = undefined
    \end{code}
  \end{tabular}
  \caption{Partial Closed Type Family}
  \label{fig:incomplete-tyfam}
\end{figure}

\subsection{Formalizing Constraint Type Families}\label{subsec:tf-constrained-formal}



\begin{figure}[ht]
  % \[
  %   \begin{array}{l l l}
  %     &\text{Type family Constructors} &\texttt{\FamCtrs}\\
  %     &\text{Type family Patterns}     &\texttt{\FamPattern}\\
  %     \\
  %     &\text{Ground Context Validity}     &\GCtxValid{\GEnv}\\
  %     &\text{Variable Context Validity}   &\VCtxValid\GEnv\VEnv\\
  %     &\text{Context Validity}            &\CtxValid\TEnv\\
  %     \\
  %     &\text{Term Typing}              &\Typing \TEnv \Tm \tau\\
  %     &\text{Coercion Typing}          &\CoTyping \TEnv \Co \Preds
  %   \end{array}
  %   \begin{array}{l l l l l}
  %     &\text{Types}           &\tau,\sigma  &\bnfeq \alpha \bnfor \tau\to\tau \bnfor \Forall\alpha\tau
  %                                              \bnfor F(\many{\tau}) \bnfor D\App\many{\tau}&\\
  %     &\text{Predicates}      &\Preds       &\bnfeq \tau\teq\tau\\
  %     &\text{Axiom Equations} &\AxiomEq     &\bnfeq \FamCtrs(\many\FamPattern) \teq \sigma\\
  %     &\text{Axiom Types}     &\AxiomTy     &\bnfeq \many\AxiomEq\\
  %     &\text{Coercions}  &\Co,\MoreCo &\bnfeq \Co\to\MoreCo \bnfor \Forall\alpha\Co
  %                                       \bnfor \Co\App\MoreCo \bnfor \FamCtrs(\many{\Co})\\
  %     &                  &            &\bnfor \refl\tau \bnfor \sym{\Co} \bnfor \comp\Co\MoreCo
  %                                       \bnfor \branch{i}{\many\tau}\\
  %     \\
  %     &\text{Ground Context} &\GEnv   &\bnfeq \empt \bnfor \GEnv,\branch{}{}:\AxiomTy\\
  %     &\text{Variable Context}&\VEnv  &\bnfeq \empt \bnfor \VEnv,x\co\tau\\
  %     &\text{Typing Context}  &\TEnv  &\bnfeq \GEnv;\VEnv\\
  %     \\
      
  %     &\text{Terms}      & \Tm        &\bnfeq x \bnfor \Lam x \tau \Tm \bnfor \Tm\App\Tm \bnfor\cast M \Co 
  %                                       \bnfor \TLam \alpha \Tm \bnfor \Tm\App\tau  \\
  %     &                  &            & \bnfor \DataCtrs\many{e} \bnfor \Case e \many{\Ptrns} \\
  %     &\text{Type family Declaration} & & \texttt{\textbf{type family}}~
  %                                         \FamCtrs\App\many{\alpha}\texttt{\textbf{ where }}
  %                                         \many{F\App\many{\tau} = \tau}
  %   \end{array}
  % \]
  \caption[Constraint Type Families System]{System for Constraint Type Families}
  \label{fig:syntax-tf-constrained}
\end{figure}

\begin{figure}[ht]
  \centering
  
  \caption[Typing Judgments for \QLTF]{Typing Judgments \QLTF{}}
  \label{fig:syntax-tf-constrained}
\end{figure}

\subsection{Type safety of \QLTF{}}\label{subsec:tf-constrained-safety} 

\newpage
\section{Related Work}\label{sec:related-work}
The novelty of functional dependencies as a language feature is the use of concepts from database theory
in functional programming\cite{codd_realtional_1970, amstrong_dependency_1974}.
They have also been formalized using constraint handling rules (CHR),
a technique from logic programming\cite{sulzmann_understanding_2007}. There is no known
implementation of functional dependencies using CHR.

There are several variations of type families that have been explored and implemented in GHC.
Open type families\cite{schrijvers_type_2008}, which predates closed type families,
are extendable in a sense that the programmer can add more equations.
To maintain both, extensibility and compatibility, open type families disallow overlapping equations.
The semantics of the instance equations is similar to that of unordered collection of type equations, unlike
closed type families, where the equations are considered in a top to bottom fashion.
Associated types\cite{chakravarty_associated_2005} are a syntactic variation of open type families.
Each typeclass has an associated type parameterized over typeclass parameters. Each instance of such typeclass
specifies what the associated type's interpretation in the context. Injective type families\cite{stolarek_injective_2015}
uses the idea from functional dependencies to specify additional injective constraints that the type family instance
should satisfy to aid type inference.

\section{Conclusion and Future Work}\label{sec:conclusion}
All three systems described in the paper have a common property that they are based on
the principle of type erasure. All the type analysis is performed at compile time and
then the types are erased from the programs.
This ensures that there is no runtime overheads because of types.
Due to type safety properties of each of these systems, we are guaranteed
that if a program passes the type check then it does not crash at runtime.
A feature that we have not included in each of the systems is the system of kinds of type of types.
They provide a way to have partially applied data constructors. The reason to not include them is that
they are orthogonal to our discussion. Adding them to the system would not change type safety of the language.

% With squinting eyes, typeclasses with functional dependencies and type families are trying to achieving the
% same goal---computation on types. While functional dependencies have a flavor of relations,
% type families have a flavor of equations. Haskell programmers using GHC,
% prefer functional programming over logic programming making type families their preferred choice.
% Further, a buggy implementation of functional dependencies in GHC, does not help its case either.
% A formal proof about the equality of the expressive power of functional dependencies and
% type families is an open problem\cite{TODO}. 

Type computation is an attractive feature for programmers with a condition that type checking and inference
is guaranteed termination. If functional dependencies are morally equivalent to type families
one would expect to have a translations that can go from one style to another.
There are two ways to do this, 1) have a translation to a common
intermediate language or 2) have translation procedures that converts one style to another. Recent work by
\citep{karachalias_elaboration_2017} explores the first idea by giving an elaboration of functional dependencies
to type families. There is no known implimentation of the algorithm given.
The type safety formalization of closed type families hinges on the assumption that
type family reduction are terminating. This problem is effectively solved by using constrained type families.
However, there is no implementation of constraints type families for the users to test it in the wild.

In conclusion, the motivation of constraint type families is to reunite
the idea of functional dependencies and type families.
The use of equality constraints to ensure that type family applications are well defined
is reminiscent of the use of functional dependencies to ensure typeclass instances are well defined.

\newpage
\bibliographystyle{ACM-Reference-Format}
\bibliography{typeclasses}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
